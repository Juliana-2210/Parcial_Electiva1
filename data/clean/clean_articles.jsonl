{"id": "Inteligencia_artificial_y_medicina", "filename": "Inteligencia_artificial_y_medicina.pdf", "title": "Una introducción a las aplicaciones de la inteligencia artificial en Medicina: Aspectos históricos", "body": "Revista Latinoamericana de Hipertensión\nISSN: 1856-4550\nlatinoamericanadehipertension@gmail.com\nSociedad Latinoamericana de Hipertensión\nVenezuela\nUna introducción a las aplicaciones de la\ninteligencia artificial en Medicina: Aspectos\nhistóricos\nArias, Víctor; Salazar, Juan; Garicano, Carlos; Contreras, Julio; Chacón, Gerardo; Chacín-González,\nMaricarmen; Añez, Roberto; Rojas, Joselyn; Bermúdez-Pirela, Valmore\nUna introducción a las aplicaciones de la inteligencia artificial en Medicina: Aspectos históricos\nRevista Latinoamericana de Hipertensión, vol. 14, núm. 5, 2019\nSociedad Latinoamericana de Hipertensión, Venezuela\nDisponible en: https://www.redalyc.org/articulo.oa?id=170262877013\nQueda prohibida la reproducción total o parcial de todo el material contenido en la revista sin el consentimiento\npor escrito del editor en jefe.\nEsta obra está bajo una Licencia Creative Commons Atribución-SinDerivar 4.0 Internacional.\nPDF generado a partir de XML-JATS4R por Redalyc\nProyecto académico sin fines de lucro, desarrollado bajo la iniciativa de acceso abierto\nRevista Latinoamericana de Hipertensión, 2019, vol. 14, núm. 5, ISSN: 1856-4550\nArtículos\nUna introducción a las aplicaciones de la inteligencia artificial en Medicina: Aspectos\nhistóricos\nAn introduction to artificial intelligence applications in medicine: Historical aspects\nVíctor Arias Redalyc: https://www.redalyc.org/articulo.oa?\nUniversidad Nacional de Colombia, Colombia id=170262877013\nhttp://orcid.org/0000-0002-2358-5908\nJuan Salazar\nCentro Investigaciones Endocrino-Metabólicas “Dr. Félix\nGómez, Venezuela\nhttp://orcid.org/0000-0003-4211-528X\nCarlos Garicano\nESE Metrosalud, Antioquia, Colombia\nJulio Contreras\nTecnológico de Antioquia, Colombia\nhttp://orcid.org/0000-0002-5179-5400\nGerardo Chacón\nUniversidad Simón Bolívar, Colombia\nhttp://orcid.org/0000-0003-3615-5787\nMaricarmen Chacín-González\nUniversidad Simón Bolívar, Colombia\nhttp://orcid.org/0000-0002-5208-9401\nRoberto Añez\nCentro Investigaciones Endocrino-Metabólicas “Dr. Félix\nGómez, Venezuela\nhttp://orcid.org/0000-0001-6363-2767\nJoselyn Rojas\nPulmonary and Critical Care Medicine Department,\nEstados Unidos\nhttp://orcid.org/0000-0003-4994-075X\nValmore Bermúdez-Pirela\nUniversidad Nacional de Colombia, Colombia\nhttp://orcid.org/0000-0003-1880-8887\nResumen:\nEn un sentido amplio la inteligencia artificial y el aprendizaje automático se ha aplicado a los datos médicos desde los inicios de\nla informática dado el profundo arraigo de esta área en la innovación, pero los últimos años han sido testigo de una generación\ncada vez mayor de datos relacionados con las ciencias de la salud, cuestión que ha dado nacimiento a un nuevo campo de las\nciencias de la computación llamado big data. Los datos médicos a gran escala (en forma de bases de datos estructuradas y no\nPDF generado a partir de XML-JATS4R por Redalyc\nProyecto académico sin fines de lucro, desarrollado bajo la iniciativa de acceso abierto 590\nVíctor Arias, et al. Una introducción a las aplicaciones de la inteligencia artificial en Medicina...\nestructuradas) si son apropiadamente adquiridos e interpretados pueden generar grandes beneficios al reducir los costos y los\ntiempos del servicio de salud, pero también podrían servir para predecir epidemias, mejorar los esquemas terapéuticos, asesorar a\nmédicos en lugares remotos y mejorar la calidad de vida. Los algoritmos de deep learning son especialmente útiles para manejar esta\ngran cantidad de datos complejos, poco documentados y generalmente no estructurados; todo esto debido a que el deep learning\npuede irrumpir al crear modelos que descubren de forma automática las características principales, así como las que mejor predicen\nel comportamiento de otras variables dentro de una gran cantidad de datos complejos. En el futuro, la relación hombre-máquina en\nbiomedicina será más estrecha; mientras que la máquina se encargará de tareas de extracción, limpieza y búsquedas de correlaciones,\nel médico se concentraría en interpretar estas correlaciones y buscar nuevos tratamientos que mejoren la atención y en última\ninstancia la calidad de vida del paciente.\nPalabras clave: Inteligencia artificial, innovación, registros médicos, bases de.\nAbstract:\nIn a broad sense, artificial intelligence and machine learning have been applied to medical data since the beginning of computing\ngiven the deep roots of this area in innovation, but recent years have witnessed an increasing generation of data related to health\nsciences, an issue that has given birth to a new field of computer science called big data. Large-scale medical data (in the form\nof structured and unstructured databases) if properly acquired and interpreted can generate great benefits by reducing costs and\ntimes of health service, but could also serve to predict epidemics, improve therapeutic schemes, advise doctors in remote places\nand improve the quality of life. e deep learning algorithms are especially useful to deal with this large amount of complex, poorly\ndocumented and generally unstructured data, all this because deep learning can break when creating models that automatically\ndiscover the predictive characteristics of a large amount of complex data. In the future, the human-machine relationship in the\nmedical evaluation will be narrower and complex; while the machine would be responsible for extraction, cleaning and assisted\nsearches, the physician will be concentrate on both, data interpretation and the best treatment option, improving the patient´s\nattention and ultimately, quality of life.\nKeywords: Artificial intelligence, innovation, medical records, databases.\nINTRODUCCIÓN\nEl cerebro humano ha evolucionado a lo largo de decenas de miles de años para percibir e interpretar estímulos\nvisuales. Sin embargo, cuando un ordenador intenta ejecutar tareas de reconocimiento de imágenes, los\nalgoritmos secuenciales utilizados en otras áreas de la computación carecen de precisión en sus resultados\n1 . Esto se debe a la incapacidad de tales algoritmos de transformar la información de bajo nivel (matriz\ntridimensional de números) a conceptos de alta complejidad tal como lo hace el humano (Figura 1); este\nproblema se conoce como vacío semántico 2 .\nFigura 1. Una sección amplificada de una fotografía muestra como realmente una computadora percibe\nuna imagen, en este caso la oreja de un perro descrita por una matriz de números.\nPDF generado a partir de XML-JATS4R por Redalyc\nProyecto académico sin fines de lucro, desarrollado bajo la iniciativa de acceso abierto 591\nRevista Latinoamericana de Hipertensión, 2019, vol. 14, núm. 5, ISSN: 1856-4550\nFIGURA 1.\nUna sección amplificada de una fotografía muestra como realmente una computadora\npercibe una imagen, en este caso la oreja de un perro descrita por una matriz de números.\nUna computadora percibe las imágenes mediante un Chip CMOS, como sucedáneo de nuestra retina,\ntraduce la intensidad de luz a señales eléctricas que posteriormente se procesan y cuantifican en unidades\nllamadas pixeles 3 . En la Figura 1 por ejemplo, aunque fácilmente un ser humano puede identificar un perro en\nla imagen, para la computadora simplemente es una matriz numérica de 301x301x3 pixeles, es decir algo más\nde medio millón de números que oscilan entre 0 (negro) y 255 (blanco), El problema consiste en averiguar\ncomo el ordenador puede traducir esta matriz a un único concepto: “perro”.\nPara dar solución a este problema, nuestro cerebro no convierte las imágenes en pixeles, sino que las\ndescompone en características como el color, la textura, forma, bordes, tamaño, ubicación, relación con otras\nimágenes, movimiento, continuidad, experiencias previas; integrando esta información en diferentes zonas\nde la corteza visual. Según la teoría más aceptada hasta la fecha, el modelo ventral-dorsal 1,4 propuesto por\nMilner y Goodale en 1992 y luego refinada por Norman en el 2000, plantea que existen dos vías bien definidas\nque transmiten información por las áreas visuales: a) La ruta dorsal: que comienza en el área V1 cruza a través\nde las áreas V2, dorso-medial (V6) y el área visual V5 y llega a la corteza parietal posterior. Esta vía se conoce\ncomo la \"ruta del dónde\" o \"ruta del cómo\", y está asociada al movimiento, representación y ubicación de los\nobjetos; el control de los ojos (movimientos del ojo de tipo sacádico) y los brazos; b) La ruta ventral comienza\nen V1 y sigue a través de las áreas V2 y V4, y de allí a la corteza temporal inferior. La ruta ventral es llamada\nla \"ruta del qué\" y está asociada al reconocimiento y representación de los objetos, también está asociada con\nel almacenamiento de la memoria de largo término y el reconocimiento de patrones. Todas las áreas en la\nruta ventral están influenciadas por factores extra-retinianos. Estos factores incluyen atención, memoria de\ntrabajo y relevancia del estímulo. Por lo tanto, esta vía no solo proporciona una descripción de los elementos\nen el mundo visual, sino que también juega un papel crucial al juzgar la importancia de estos elementos.\nEstas bases fisiológicas constituyen los elementos fundamentales del aprendizaje automático, el cual\nrepresenta una potencial herramienta bioinformática para el procesamiento de datos en la actualidad. Por\nello, en esta revisión se describe la evolución historia del deep learning, como un componente de la inteligencia\nartificial y su posible utilización en la medicina moderna.\nPDF generado a partir de XML-JATS4R por Redalyc\nProyecto académico sin fines de lucro, desarrollado bajo la iniciativa de acceso abierto 592\nVíctor Arias, et al. Una introducción a las aplicaciones de la inteligencia artificial en Medicina...\nEnfoque basado en datos o aprendizaje automático\nCon el enfoque del aprendizaje automático se intenta emular la característica humana de experiencias\nprevias, para esto se le proporciona al ordenador gran cantidad de imágenes cada una de estas con la etiqueta\ncorrespondiente al concepto que se desea reconocer (datos de entrenamiento) con el objetivo de entrenar un\nconjuntos de hipótesis o posibles técnicas que aprendan la apariencia visual de cada concepto, seleccionando\naquella técnica que de la mejor solución, es decir que pueda predecir con la mayor precisión las etiquetas de\nnuevas imágenes no usadas en la etapa de entrenamiento (datos de prueba), este enfoque de acumulación de\ndatos se representa en la Figura 2.\nFIGURA 2\nPara reconocer si un paciente tiene cierta enfermedad o no, el ordenador obtiene un conjunto\nde datos mixtos el cual divide entre datos de entrenamiento y de prueba, una vez el algoritmo\nseleccionado es entrenado, se evalúa la precisión del modelo al predecir etiquetas de datos de prueba.\nAprendizaje automático basado en el funcionamiento del cerebro\nEl término deep learning se refiere a un conjunto de métodos que permiten a una computadora descubrir\nautomáticamente las características de alto nivel necesarias para la clasificación a partir de los datos en su\nestado natural utilizando múltiples capas de representación. El método intenta imitar la actividad en capas de\nneuronas en el neocórtex, sector que agrupa el ochenta por ciento del cerebro y donde ocurre el pensamiento.\nEl soware aprende, en un sentido muy real, a reconocer patrones en las representaciones digitales de sonidos,\nimágenes y otros datos 5 .\nEl deep learning tiene el potencial de transformar una gama de sectores, no menos importante, el\nrelacionado con la salud. Donde se le conoce como medicina de caja negra, porque aunque el algoritmo es\ncapaz de diagnosticar lesiones cutáneas potencialmente malignas con la misma precisión que un dermatólogo\ncertificado 6 , las reglas para diagnosticar si es benigna o no son definidas por él mismo, y a menudo sin dejar\nun registro claro que explique sus decisiones 7 . Aun así, las ventajas son mucho mayores, el deep learning\njunto a los especialistas del sector pueden hacer del diagnóstico médico una tarea más rápida y precisa\n(inmensas posibilidades para mejorar los diagnósticos, la creación de vías de atención y la reproducibilidad\nen los procedimientos quirúrgicos para, en última instancia, lograr mejores resultados clínicos.), por ejemplo,\nArterys, un sistema de imagenología cardíaca asistido por Inteligencia Artificial (IA) y entrenado con 3.000\nPDF generado a partir de XML-JATS4R por Redalyc\nProyecto académico sin fines de lucro, desarrollado bajo la iniciativa de acceso abierto 593\nRevista Latinoamericana de Hipertensión, 2019, vol. 14, núm. 5, ISSN: 1856-4550\ncasos cardiacos en los que se analizó el corazón y el flujo sanguíneo, al estar conectado a una máquina de\nresonancia magnética, puede examinar el flujo sanguíneo y las imágenes obtenidas para generar contornos\neditables proporcionando una imagen precisa de un corazón en segundos, un proceso que dura normalmente\nuna hora de trabajo manual y que no requiere un pensamiento creativo, esto redunda en que el especialista\ntendrá más tiempo para dedicarse a idear otros tratamientos potenciales 8 .\nBreve historia del deep learning\nEl perceptrón\nUna red neuronal biológica se considera el sistema mejor organizado para procesar información de\ndiferentes sentidos tales como la vista, el oído, el tacto, el gusto y el olfato de una manera eficiente. Uno\nde los mecanismos clave para el procesamiento de la información en un cerebro humano es la complicada\ninformación de alto nivel que se procesa mediante las conexiones (llamadas sinapsis), de un gran número de\nelementos estructuralmente simples (llamados neuronas). En el aprendizaje automático, las redes neuronales\nartificiales son una familia de modelos que imitan la elegancia estructural del sistema neural y aprenden\npatrones inherentes a las observaciones 9 , la similitud puede apreciarse en la Figura 3.\nFIGURA 3\n(a) Diagrama que muestra como el funcionamiento y la estructura de\nlas redes neuronales biológicas inspiraron el funcionamiento netamente\nmatemático del primer modelo de neurona artificial, el perceptrón (b).\nLa idea nace de los trabajos del psicólogo Frank Rosenblatt quien desarrolló el perceptrón 10 , el primer\nalgoritmo para entrenar una red neuronal basado en los trabajos de McCulloch y Pitts 11 , que aunque no sigue\nexactamente el funcionamiento de las redes biológicas, produce un resultado simple, una neurona suma las\nmúltiples entradas ponderadas por la medida de la fuerza de conexión sináptica (parámetros), la suma se hace\npasar por una función de activación no lineal o estado de la neurona (las funciones no lineales se usan para\nmodelar dinámicas relativamente complejas), múltiples neuronas pueden apilarse en una capa para generar\nmúltiples salidas, los parámetros de esas neuronas son recalculados con el fin de disminuir la medida de la\ndiferencia entre la salida deseada y la salida real, conocida como error (Figura 4).\nPDF generado a partir de XML-JATS4R por Redalyc\nProyecto académico sin fines de lucro, desarrollado bajo la iniciativa de acceso abierto 594\nVíctor Arias, et al. Una introducción a las aplicaciones de la inteligencia artificial en Medicina...\nFIGURA 4.\nCada neurona aprende a identificar un número, la medida de la diferencia de\nlas salidas se conoce como error que ajusta los parámetros de forma optima\nPosteriormente en 1969 Minsky publicó junto con Papert la obra “Perceptrons” 12 , donde mostraron todas\nlas limitaciones de los perceptrones, en particular el aprendizaje en clases que no son linealmente separables\ncomo la función XOR (función lógica OR exclusiva), el argumento principal de Minsky en contra de los\nperceptrones, era que el algoritmo de aprendizaje de Rosenblatt no trabajaba para múltiples capas, ya que\nsolo especifica la salida correcta para la capa de salida, así que no era posible calcular los parámetros correctos\npara las capas intermedias, esto llevo a las redes neuronales a un periodo de pocos progresos.\nLas redes neuronales pueden organizarse en múltiples capas\nDurante varios años las perspectivas no fueron buenas para las redes neuronales pero, ¿Por qué?, La idea\ndel conexionismo era usar muchas capas de neuronas matemáticamente simples para resolver problemas\ncomplejos. La solución fue el desarrollo de un procedimiento de aprendizaje para redes neuronales más\nsofisticadas que los simples perceptrones, creando representaciones internas o subprocesos de una tarea en\nparticular, estas representaciones son modeladas por capas “ocultas” con estados no especificados por la tarea\ntal como se muestra en la Figura 4, el nivel de sofisticación de estas redes permite al menos teóricamente\nimplementar cualquier función computable 13 .\nPropagación hacia atrás\nAhora que se conocían las ventajas y utilidad de una arquitectura multicapa en una red neuronal, se\ndebía buscar una forma práctica para el ajuste de los parámetros de las capas ocultas con los ejemplos de\nentrenamiento, con la finalidad de minimizar el error a un valor cercano a cero. Una manera elegante de\nresolver este problema fue el diseño de un algoritmo llamado “propagación hacia atrás”, que utiliza la regla\nde cadena (ecuación utilizada en cálculo para hallar la derivada de funciones anidadas), es decir dado que la\nsalida depende de la salida de las neuronas en la capa oculta, el cálculo asigna parte de la “culpa” del error a las\nneuronas de la capa oculta inmediatamente anterior, esta a su vez a la anterior si existe, así hasta propagar el\nerror hacia atrás. De esta forma se conoce cuanto cambia el error en la salida si se cambia cualquier parámetro\nde la red, incluidos aquellos en las capas ocultas, por último para encontrar los parámetros óptimos se recurre\npor lo general, a una técnica llamada gradiente descendente estocástico (SGD).\nAunque varias investigaciones usaron esta técnica en computadoras 14 , no fue hasta la tesis doctoral de\nPaul Werbos que se estudió en profundidad el entrenamiento de redes neuronales multicapas usando la\npropagación hacia atrás 15 , aunque a su aplicación no se le prestó atención debido a los efectos adversos\ndel periodo oscuro de las redes neuronales. Sin embargo, su trabajo fue descubierto y popularizado una\ndécada después por Rumelhart, Hinton y William1 6 , quienes siguiendo esta línea publicaron otro artículo\nPDF generado a partir de XML-JATS4R por Redalyc\nProyecto académico sin fines de lucro, desarrollado bajo la iniciativa de acceso abierto 595\nRevista Latinoamericana de Hipertensión, 2019, vol. 14, núm. 5, ISSN: 1856-4550\ndonde presentaban el nuevo algoritmo de aprendizaje y abordaron los problemas discutidos por Minsky\nen “Perceptrons” 12 . Esta formulación hizo comprender cómo las redes de neuronas multicapa podían ser\nentrenadas para abordar complejos problemas de aprendizaje 17 .\nLas redes neuronales aprenden a ver\nLas redes neuronales resultan ser efectivas al entrenarse con data estructurada, por ejemplo: base de datos\nde precios de casas en función de sus características, la relación entre fenotipos metabólicos y los niveles de\ninsulina plasmática. Pero se les dificulta manejar datos no estructurados como una imagen médica, una pieza\nde sonido o un historial médico electrónico 18 .\nEn el caso de datos no estructurados, por ejemplo una imagen, está compuesta de una matriz de datos,\ndonde cada dato representa la intensidad de un pixel, cada pixel se convierte en una entrada a la red, esto\ncausa que la neurona solo puede recibir un valor por cada entrada, por lo tanto la imagen debe ser aplanada, es\ndecir cada fila de la matriz se apila al lado de la siguiente, convirtiéndose en un vector muy largo; si se trabaja\ncon una imagen de 40x40 pixeles y suponiendo que se encuentra en escala de grises, se tendrá 1600 variables\nde entrada. El aplanamiento causa que se pierda toda relación espacial de un pixel con sus pixeles vecinos, en\nesta relación está la clave de muchos algoritmos de pre-procesamiento de imágenes 19-21 .\nLas Redes Neuronales Convolucionales (CNN, pos sus siglas en inglés) funcionan de forma diferente pues\nen lugar de aplanar la imagen y usar un vector de pixeles usan una matriz más pequeña conocida como filtro\no detector de características, en la Figura 5 se muestran filtros como una matriz de 2x2, la cual pondera a\ncada subconjunto de 2x2 en la matriz de la imagen, la suma de todas las ponderaciones se almacena como un\ndato de una nueva matriz conocida como mapa de características, se crean distintos mapas de características\nusando valores distintos en la matriz de filtros para construir la primera capa convolucional.\nFIGURA 5\nArquitectura de una Redes Neuronales Convolucionales\nn no lineal (ReLU) al mapa de características y al igual que las redes neuronales es necesaria una función no\nlineal a la salida, dada la naturaleza de los datos de entrada, en general se considerara al mapa de características\njunto a la función no lineal ReLU como una única capa convolucional. La siguiente capa se conoce como\npooling o muestreo, la cual básicamente toma una sección del mapa de características y extrae un valor\nrepresentativo, en el caso del max pooling el máximo valor en la sección muestreada. La capa pooling es\nuna versión reducida del mapa de características, esta capa es importante dado que dota al modelo de\ninvariabilidad, es decir si el objetivo es detectar una microfractura, el tipo de microfractura, el tamaño de\nla microfractura, los artefactos usados para la radiografía, la posición de la microfractura, entre otros; es\nirrelevante para el modelo y siempre intentará detectarla como una microfractura.\nLa red mostrada en la Figura 5 exhibe el esquema básico de una secuencia convolucional-ReLU-muestreo,\ndonde la última capa pooling se aplana y sirve como entrada a una red neuronal que se encarga de la\nPDF generado a partir de XML-JATS4R por Redalyc\nProyecto académico sin fines de lucro, desarrollado bajo la iniciativa de acceso abierto 596\nVíctor Arias, et al. Una introducción a las aplicaciones de la inteligencia artificial en Medicina...\nclasificación. En este caso, el entrenamiento de los parámetros que forman los filtros CNN es similar al de\nlas redes neuronales. El desarrollo de esta topología vino en 1989, cuando LeCun et al., en los laboratorios\nBell de AT&T demostró una muy significativa aplicación en la detección de números escritos a mano con\nel fin de reconocer el código postal en una carta 22 . Las CNN se inspiraron en la naturaleza jerárquica de\nlas redes neuronales en la corteza visual descubierta por Huber y Wiesel 23 donde una célula en una etapa\nsuperior tiende a responder selectivamente a una característica más complicada del patrón de estimulo y, al\nmismo tiempo, tiene un campo receptivo más grande, y es más insensible al cambio de posición del patrón\nde estímulo. A mediados de los 90’s los trabajos de LeCun resultaron en la mayor aplicación comercial de\nlas CNN hasta esa fecha, la lectura automática de cheques 24 que a finales de los 90’s procesaban cerca del\n20% de los cheques en los EEUU.\nLas redes neuronales comprenden el lenguaje hablado y escrito\nAl igual que la escritura, la compresión del lenguaje (en cualquier idioma) por una máquina es otro\nproblema difícil de resolver debido a las casi infinitas variaciones que podemos obtener al pronunciar\npalabras (acento, tono de voz, velocidad, entonación, etc.), sumado a todo esto, se sobre-impone otro desafío\nque resolver: largas secuencias de entrada generadas en tiempo real. En el caso de las imágenes, resulta\nrelativamente fácil usar una red neuronal que sustraiga e identifique una letra dentro una imagen, sin\nembargo, el proceso que debe realizarse con un archivo de audio o una conversación no es tan simple ya que:\nprimero separar el habla en caracteres es completamente impráctico e incluso encontrar palabras individuales\ndentro de una conversación no es fácil y segundo el contexto de la conversación (si se comprende) hace\nmucho más fácil encontrar el significado de cada palabra en contraposición a reconocer y definir cada palabra\nindividualmente.\nSi bien la estructura de una CNN funciona bastante bien para las imágenes, no es en absoluto adecuado\npara largos flujos de información continua con significado en tiempo y espacio (como el audio o el texto),\npues la red neural carece de \"memoria\" que permita que una entrada pueda afectar a otra entrada procesada\nposteriormente. En otras palabras, una red capaz de procesar lenguaje debe ser capaz de manejar una cadena\nde palabras o de sonidos que se suman en el tiempo y que globalmente entregan un significado en lugar de\nuna sola entrada de gran información que se entrega completa de una sola vez.\nPara abordar el problema de la comprensión del habla, los investigadores trataron de modificar las redes\nneuronales para procesar la entrada como un flujo de datos continuos (en lugar de grandes lotes como en\nlas imágenes). Para ello crearon una versión aplanada de la red neuronal (Figura 6), a la vez que la capa\noculta tiene una bifurcación que se redirige al cuerpo de la neurona. La Figura 7 muestra la forma común\nde representar una Red Neuronal Recurrente (RNN, por sus siglas en inglés), que al desenrollarse exhibe\nmúltiples copias de la misma red que pasan el mensaje de una copia a otra. Las bases de este tipo de arquitectura\nde red neuronal se remontan a los trabajos de Waibel et., al en redes neuronales con retardos de tiempo 25 .\nPDF generado a partir de XML-JATS4R por Redalyc\nProyecto académico sin fines de lucro, desarrollado bajo la iniciativa de acceso abierto 597\nRevista Latinoamericana de Hipertensión, 2019, vol. 14, núm. 5, ISSN: 1856-4550\nFIGURA 6.\nArquitectura simple de una red neuronal multicapa\nFIGURA 7.\nArquitectura de una Red Neuronal Recurrente\nEn este sentido, las RNN son bastantes similares a las CNN, pero en lugar de adquirir todos los datos\nal mismo tiempo, cada neurona observa solo un subconjunto de la entrada por ejemplo en la Figura 7: “Yo\nsoy de Colombia”, sería un subconjunto visto por la red en un tiempo determinado, a cada uno de estos\nsubconjuntos se le aplica el mismo cálculo, pero hasta allí llegan las similitudes. En las CNN no existe el\nconcepto de redes que se bifurcan sobre si mismas en el tiempo, además en las RNN hay entradas y salidas\nsecuenciales de datos en lugar de un recorrido por toda la data de entrada para generar un resultado como es\nel caso de las capas de las CNN. Dada la naturaleza cíclica de la red, el concepto de propagar el error hacia\natrás no aplicaría, la solución es desenrollar la red tal como se mostró en la Figura 8, tratando cada bucle a\ntravés de la red neuronal como una entrada a otra red neuronal por un número limitado de veces, proceso\nconocido como propagación hacia atrás a través del tiempo 26 .\nPDF generado a partir de XML-JATS4R por Redalyc\nProyecto académico sin fines de lucro, desarrollado bajo la iniciativa de acceso abierto 598\nVíctor Arias, et al. Una introducción a las aplicaciones de la inteligencia artificial en Medicina...\nFIGURA 8.\nAlgoritmo de propagación hacia atrás del error\nEn experimentos posteriores, Bengio demostraría la dificultad de entrenar una RNN de forma óptima\n27 , debido a que los parámetros de la red solo tienen en cuenta dependencias a corto plazo. Por ejemplo,\nconsiderando un modelo de lenguaje que intenta la predicción de una palabra basada en las palabras anteriores\nen una frase: si el objetivo es predecir la última palabra en “Jorge está durmiendo en su cama” no se necesita\notro contexto para saber que la última palabra es cama. En este caso cuando la brecha de información relevante\ny el lugar que se necesita es pequeño, las RNN pueden aprender a usar la información pasada. Pero en el caso\ndonde la brecha entre la información relevante y el punto donde se necesita puede llegar a ser grande, como en\nla frase “Soy Colombiano… hablo con fluidez español”, el contexto se encuentra en Colombiano, pero dada\nla distancia es posible que la red no trabaje correctamente. Este fenómeno se puede observar detalladamente\nen la Figura 9, pues el algoritmo de propagación hacia atrás no trabaja adecuadamente para RNN con largas\ndependencias (en realidad, la propagación hacia atrás no trabaja bien para redes muy largas).\nPDF generado a partir de XML-JATS4R por Redalyc\nProyecto académico sin fines de lucro, desarrollado bajo la iniciativa de acceso abierto 599\nRevista Latinoamericana de Hipertensión, 2019, vol. 14, núm. 5, ISSN: 1856-4550\nFIGURA 9.\n(a) Red Neuronal Recurrente con dependencias cortas\n(b) Red Neuronal Recurrente con dependencias largas\nArquitecturas profundas\nDiverso resultados teóricos revisados sugieren que para aprender el tipo de funciones complicadas que\npueden representar abstracciones de alto nivel (por ejemplo, visión y lenguaje), se requieren arquitecturas\nprofundas, este tipo de arquitecturas requieren muchas menos neuronas en total, resultando en una\nreducción del número de parámetros, lo que permite entrenar redes con una base de datos relativamente\npequeña29. Pero más importante aún, en comparación con la arquitectura superficial que necesita\nun extractor de características \"bueno\", diseñado principalmente por las habilidades de ingeniería o\nconocimiento de dominio experto, los modelos profundos son buenos para descubrir las características\nautomáticamente de forma jerárquica 9 .\nVanishing gradient problem\nLa clave del “deep learning” es tener muchas capas en los sistemas actuales de hasta veinte o más, pero ya a\nfinales de los ochenta se sabía que las redes neuronales con muchas capas entrenadas con propagación hacia\natrás simplemente no funcionaban bien, y en particular no funcionaba tan bien como las redes con menos\ncapas 29 . Pues bien, teniendo en cuenta que el error en la salida se propaga hacia atrás, todas las neuronas en\nla red actualizan los parámetros de aprendizaje en función del valor de la culpa adjudicado a cada neurona.\nAhora al actualizarse, esos parámetros son multiplicados por las salidas de una neurona para convertirse en la\nentrada de la próxima y así sucesivamente hasta llegar a la salida, el problema ocurre cuando el error empieza\na disminuir, los valores del error que se propagan hacia las capas más cercanas a la entrada son muy pequeños,\ny por lo tanto los parámetros de aprendizaje en esas capas se actualizan de forma más lenta, el resultado\nes que luego de varias iteraciones las capas más próximas a la entrada no alcanzan a actualizarse hasta sus\nvalores óptimos en un tiempo razonable, y más importante aún, son estas capas las responsables de extraer las\nPDF generado a partir de XML-JATS4R por Redalyc\nProyecto académico sin fines de lucro, desarrollado bajo la iniciativa de acceso abierto 600\nVíctor Arias, et al. Una introducción a las aplicaciones de la inteligencia artificial en Medicina...\ncaracterísticas básicas que luego serán usadas por las capas de orden superior, este es el problema que dificulta\na las RNN tener memoria de largo plazo 30,31 .\nEn el caso de las RNN. la solución llego usando un nuevo concepto conocido como Memoria de Corto\ny Largo Plazo (LSTM, por sus siglas en inglés) trabajo hecho por dos importantes investigadores en RNN\nSchmidhuber y Hochreiter 32 , pero, esto hizo poco para arreglar el problema más grande, la percepción de que\nlas redes neurales eran poco fiables y no trabajaron muy bien. Las computadoras además no tenían la suficiente\nvelocidad de procesamiento y no había suficientes datos, esto hizo que los investigadores perdieran la fe en\neste enfoque de IA. De esta manera, mediados de los años 90 el estudio de las redes neuronales se estancó\nde nuevo y un método denominado Maquinas de Vectores de Soporte (SVM, por sus siglas en inglés), que\nen términos muy sencillos podría describirse como una forma matemáticamente óptima de formación de un\nequivalente a una red neuronal de dos capas, se desarrolló y empezó a considerarse superior a las complicadas\nredes neuronales 33 .\nLa conspiración del “deep learning”\nCon el ascenso de las SVM, el vanishing gradient problem, la falta de datos y una velocidad de\nprocesamiento insuficiente, el nuevo milenio fue un tiempo oscuro para la investigación en redes neuronales.\nPero todo empezó a cambiar cuando el Instituto Canadiense para Estudios Avanzados apoyó a un pequeño\ngrupo de investigadores para que siguiera trabajando en el tema. Como lo diría Geoffrey Hinton, quien dirigía\nel proyecto, ellos tramaron una conspiración; dado el estigma de las redes neuronales se decidió \"rebautizar\"\nel campo con el nombre de deep learning.\nPero más importante que el nombre fue la idea, en su trabajo revolucionario de 2006 34 , el equipo demostró\nque las redes neuronales con muchas capas podría ser bien entrenadas si los parámetros se inician de una\nmanera inteligente en lugar de aleatoria, que era la manera como se hacía hasta ese momento, pero ¿Cuál es\nla manera inteligente de inicializar los parámetros?, la solución era usar un nuevo algoritmo, las máquinas\nrestrictivas de Boltzmann.\nMáquinas Restrictivas de Boltzmann (RBM)\nLas RBM son redes neuronales superficiales de dos capas, la primera capa se denomina capa visible (o,\nde entrada) y la segunda, denominada capa oculta. Las RBM se caracterizan por el hecho que no existe\ncomunicación intra-capa entre nodos, en este punto los parámetros son inicializados aleatoriamente; si los\ndatos son imágenes en escala de grises, por ejemplo, cada pixel es asignado a cada nodo de la capa visible, la\nmultiplicación de cada uno de estos pixeles por los parámetros en la red, sirven como entrada a la capa oculta,\nalimentando la función no lineal de salida de cada una de las neuronas de esta capa, la salida de una RBM se\nconecta a la entrada de la siguiente, así sucesivamente hasta la capa final que genera la salida deseada (Figura\n10).\nPDF generado a partir de XML-JATS4R por Redalyc\nProyecto académico sin fines de lucro, desarrollado bajo la iniciativa de acceso abierto 601\nRevista Latinoamericana de Hipertensión, 2019, vol. 14, núm. 5, ISSN: 1856-4550\nFIGURA 10\nFigura 10\nLa siguiente fase es una reconstrucción de la base de datos de una forma no supervisada (no supervisada se\nrefiere al hecho de que el modelo no conoce el resultado correcto en un ejemplo de entrenamiento, es decir\nque no se conoce a la salida). El procedimiento es usar el resultado de la RBM como entrada a la capa visible,\nuna vez que cada salida es multiplicada por los parámetros intermedios, la sumatoria alimenta la función no\nlineal que genera una reconstrucción de la entrada, esto es, una aproximación al valor de los pixeles de la\nimagen, tal como se muestra en la Figura 11 35 .\nPDF generado a partir de XML-JATS4R por Redalyc\nProyecto académico sin fines de lucro, desarrollado bajo la iniciativa de acceso abierto 602\nVíctor Arias, et al. Una introducción a las aplicaciones de la inteligencia artificial en Medicina...\nFIGURA 11.\nFigura 11.\nDado que los parámetros de una RBM se inicializan aleatoriamente, la medida de la diferencia entre la\nimagen reconstruida y la original (conocida como error de reconstrucción) es grande, este error se propaga\nhacia atrás para ajustar los parámetros en un proceso iterativo igual al aplicado en las RNA estándar. La salida\nde la Figura 10 se puede definir como la probabilidad de que la salida sea dada parametrizado por : , en el caso\nde la Figura 11, el resultado es la probabilidad de que la salida sea dado parametrizada por : .\nEl proceso de reconstrucción estima la distribución de probabilidad de la entrada original; esto es, los\nvalores de muchos pixeles a la vez, este tipo de algoritmos se conocen como modelos generativos 36 , que\ndifieren al llamado aprendizaje discriminatorio realizado por la clasificación, que discrimina las entradas\nentre clases o etiquetas. Las RBM utilizan la divergencia de Kullback-Leibler para medir la distancia entre\nla distribución de probabilidad estimada y la distribución real de la entrada 37 , midiendo las áreas no\nsuperpuestas o divergentes bajo las dos curvas, tal como se muestra en la Figura 12.\nPDF generado a partir de XML-JATS4R por Redalyc\nProyecto académico sin fines de lucro, desarrollado bajo la iniciativa de acceso abierto 603\nRevista Latinoamericana de Hipertensión, 2019, vol. 14, núm. 5, ISSN: 1856-4550\nFIGURA 12.\nFigura 12.\nEl algoritmo de propagación hacia atrás de las RBM intenta minimizar esas áreas de modo que las entradas\nponderadas por los parámetros compartidos, produzcan una aproximación cercana a la entrada original.\nA la izquierda de la Figura 12 está la distribución de probabilidad de un conjunto de entrada original ,\nyuxtapuestos a la distribución reconstruida ; mientras que a la derecha, la integración de sus diferencias.\nMediante el ajuste iterativo de los pesos según el error que producen, un RBM aprende a aproximar los datos\noriginales. Se podría decir que los pesos vienen lentamente a reflejar la estructura de la entrada, que se codifica\nen las activaciones de la primera capa oculta. El proceso de aprendizaje se parece a dos distribuciones de\nprobabilidad que convergen paso a paso 38 .\nBengio et al. 39 , continuaron sus investigaciones y en un reporte en 2007 argumentaron que los métodos\ncon muchos pasos de procesamiento, o de manera equivalente con representaciones jerárquicas de los\ndatos, son más eficientes para problemas difíciles que los métodos superficiales como las SVM. También\npresentaron razones de la importancia del pre-entrenamiento no supervisado, y concluyeron que esto no sólo\ninicializa los pesos de una manera más óptima, sino lo que es más importante conduce a representaciones más\nútiles aprendidas de los datos.\nPara el año 2012 los avances en el uso de Unidades de Procesamiento Gráfico (GPUs, por sus siglas\nen inglés) 40 , la técnica de dropout para prevenir el sobre-entrenamiento 41 y el uso de la función de\nactivación ReLU para prevenir el desvanecimiento del gradiente por saturación 42-45 , fueron usados por una\nred convolucional profunda para batir el récord en 10,8% en el desafío de reconocimiento visual a gran escala\nen ImageNet con 1,3 millones de imágenes de alta resolución, cuyo objetivo es discriminar cerca de 1000\nclases diferentes 46 .\n“Deep learning” y datos médicos\nEs importante recordar que la IA (en el sentido amplio) y el aprendizaje automático se ha aplicado en el\nanálisis de datos médicos, incluidos los estudios por imágenes desde los primeros días de la informática 47 .\nLos sistemas de diagnóstico asistido por ordenador han existido desde los años setenta 48 , el procesamiento\nautomatizado y el análisis de señales de tiempo unidimensionales (por ejemplo, electrocardiogramas) ha\nexistido durante décadas 49 , pero los últimos 10 años han sido testigo de una generación cada vez mayor de\ndatos relacionados con las ciencias de la salud, cuestión que nos ha llevado a ingresar en un campo de las\nciencias de la computación llamado big data y a una nueva disciplina llamada big data analysis 50 .\nLos datos médicos a gran escala (en forma de bases de datos estructuradas y no estructuradas) si son\napropiadamente adquiridos e interpretados pueden generar grandes beneficios al reducir los costos del\nservicio de salud (lo cual ya en la actualidad se está utilizando), pero también podrían servir para predecir\nepidemias, mejorar los esquemas terapéuticos, asesorar a médicos en lugares remotos y mejorar la calidad de\nvida de pacientes. El objetivo ahora es entender la mayor información sobre un paciente y tan temprano en\nPDF generado a partir de XML-JATS4R por Redalyc\nProyecto académico sin fines de lucro, desarrollado bajo la iniciativa de acceso abierto 604\nVíctor Arias, et al. Una introducción a las aplicaciones de la inteligencia artificial en Medicina...\nsu vida como sea posible, detectando señales de una enfermedad peligrosa en una etapa temprana en la cual\nque el tratamiento sea más simple (y menos costoso) que en una etapa mucho más avanzada 51 .\nLamentablemente, la mayoría de los datos de salud están menos organizados y estandarizados que los\ndatos de imágenes médicas. Por ejemplo, en muchos países aún las historias clínicas se encuentran con base\nanalógica en papel y en aquellos países que cuentan con registros electrónicos, la información es altamente\nheterogénea y muchas veces, inconsistente, que incluye datos demográficos, diagnósticos, procedimientos,\nresultados de pruebas de laboratorio y medicamentos, así como notas clínicas no estructuradas en texto\nlibre. En este contexto, es muy difícil al menos en la actualidad, para los modelos de aprendizaje profundo\n(como lo es para el cerebro humano) reconocer patrones confiables de información dispersa y ruidosa que\nde información estructurada.\nDe igual manera, resulta dispendioso el tiempo en que el médico debe ingresar información dentro del\nsistema (o en papel) que le suministra un paciente en vez de utilizar este tiempo en la valoración clínica del\nmismo o dedicar más tiempo al paciente en la educación o explicaciones sobre su patología. En este caso\nen particular, existe investigación muy activa en el desarrollo de un sistema basado en machine learning u\notras técnicas de IA capaces de reconocer el lenguaje natural de la relación médico paciente y realizar las\nanotaciones pertinentes derivadas de la conversación entre ambos. Esto es de vital interés en el área de salud,\npues ha sido consistentemente reportado que la documentación de datos clínicos, su búsqueda y posterior\nrevisión es la causa principal de pérdidas en la productividad del médico en los EUA. De hecho, se estima que\nun médico en promedio invierte del 34 al 55% de su día laboral haciendo anotaciones y revisando registros\nmédicos electrónicos en menoscabo de la interacción directa con sus pacientes 52 .\nOtro desafío relacionado con lo anterior es que los pacientes con un estatus socioeconómico bajo pueden\ntener datos particularmente no confiables, tales como información faltante o incorrecta dentro de los\nregistros electrónicos de salud o más aún en los analógicos, debido a la recepción de atención fragmentada en\nmúltiples instituciones que no están interconectadas. En estos casos, los algoritmos de aprendizaje profundo\npueden ser de poca ayuda para estos pacientes reforzando las inequidades de salud ya existentes.\nLos algoritmos de deep learning son especialmente útiles para tratar gran cantidad de datos, especialmente\nde naturaleza compleja, poco documentados y generalmente no estructurados, como por ejemplo imágenes,\nregistros médicos electrónicos, datos de sensores, entre otros. El aprendizaje automático tradicional requiere\nla extracción de características de los datos antes de ser implementada sobre los modelos, esto adiciona el\nproblema de la necesidad de un profundo conocimiento del área, y que, aun teniendo al personal idóneo, la\ngran cantidad de variables pueden desbordar la capacidad del profesional para encontrar nuevos patrones.\nEn este escenario, el deep learning puede irrumpir al crear modelos que descubren de forma automática las\ncaracterísticas predictoras de una gran cantidad de datos complejos 53 .\nAunque se encuentra en pleno desarrollo, la aplicación de estos algoritmos en el área médica ha dado\nresultados importantes a varios desafíos, tal es el caso de la detección de mitosis anormales en imágenes\nhistológicas de cáncer de mama usando CNN profunda49. Otro avance importante es la clasificación de\nmutaciones con el fin conocer la probabilidad de que alguna alteración genética cause una enfermedad, esto\nse ha utilizado para descubrir nuevos determinantes genéticos del autismo, cánceres de tipo hereditarios y la\natrofia muscular espinal 1,54 . El descubrimiento de compuestos bioactivos con los efectos farmacológicos y\nsu modificación químico-estructural para mejorar su potencia y el diagnóstico precoz de la enfermedad de\nAlzheimer en su etapa prodrómica – el deterioro cognitivo leve- son aplicaciones que han despertado gran\ninterés en la comunidad médica, que espera su rápido desarrollo y una mejor interoperabilidad en los modelos\n55 .\nSon varias las áreas donde la inteligencia artificial ha logrado sus mejores aportes en el área de biomedicina,\nun área clásica de desarrollo ha sido la visión por computadora y el reconocimiento de objetos (OR). La\nprimera se enfoca en la comprensión de imágenes y video, además de ocuparse de tareas como la clasificación,\nPDF generado a partir de XML-JATS4R por Redalyc\nProyecto académico sin fines de lucro, desarrollado bajo la iniciativa de acceso abierto 605\nRevista Latinoamericana de Hipertensión, 2019, vol. 14, núm. 5, ISSN: 1856-4550\ndetección y segmentación de objetos, que son útiles para determinar si un estudio por imágenes de un paciente\ncontiene alguna estructura anormal como una tumoración. Muchos estudios han demostrado resultados\nprometedores en diagnósticos complejos que abarcan dermatología, radiología, oalmología y anatomía\npatológica; los diagnósticos a nivel de imagen han tenido bastante éxito al emplear métodos basados en CNN,\nesto se debe en gran parte al hecho de que las CNN han logrado un desempeño igual al humano en tareas de\nclasificación de objetos, en las cuales aprenden a clasificar el objeto contenido en una imagen 56 .\nDe manera similar, los algoritmos de detección y segmentación de objetos identifican partes específicas de\nuna imagen que corresponden a objetos particulares, los métodos CNN toman los datos de la imagen como\nentrada y lo deforman iterativamente a través de una serie de operaciones convolucionales y no lineales hasta\nque la matriz de datos sin procesar original se transforma en una distribución de probabilidad sobre posibles\nclases de imagen. Sorprendentemente, los modelos de aprendizaje profundo han logrado una precisión a nivel\nmédico en una amplia variedad de tareas de diagnóstico, incluida la identificación de lunares de melanomas,\nretinopatía diabética, riesgo cardiovascular y estudios de fondo de ojo y tomografía de coherencia óptica, la\ndetección de lesiones mamarias en mamografías y la búsqueda de lesiones en la columna a partir de imágenes\nde resonancia magnética 57 .\nUna segunda área de gran interés es el procesamiento del lenguaje natural (PNL), el cual se centra en\nanalizar el texto y el habla para inferir el significado de las palabras. En este caso, las RNN son efectivas\nen el procesamiento de entradas secuenciales, como el lenguaje, el habla y los datos de series de tiempo.\nLos éxitos más interesantes en las PNL incluyen la traducción automática, la generación de texto y la sub-\ntitulación de imágenes. En salud, las tecnologías de aprendizaje profundo y de lenguaje secuenciales potencian\nlas aplicaciones en dominios como los registros de salud electrónicos ya mencionados. La historia clínica\ndigitalizada de una gran organización médica puede capturar las transacciones médicas de más de 10 millones\nde pacientes a lo largo de una década 58,59 , una sola hospitalización por sí sola generalmente genera unos\n150.000 datos.\nEs por esto que la aplicación de métodos de aprendizaje profundo a los datos registrados electrónicamente\nes un área en rápida expansión. En este momento, al hacer predicciones en medicina la mayoría de los estudios\nhan utilizado aprendizaje supervisado en conjuntos limitados de datos estructurados, que incluyen resultados\nde laboratorio, signos vitales, códigos de diagnóstico y datos demográficos. Para dar cuenta de los datos\nestructurados y no estructurados que contienen las historias médicas digitales y analógicas (en papel), los\ninvestigadores están empezando a emplear enfoques de aprendizaje no supervisados en los cuales las redes se\nentrenan primero para aprender representaciones útiles mediante la compresión y luego la reconstrucción\nde datos sin etiquetar, para predecir diagnósticos específicos.\nConclusiones\nEl aprendizaje automático no es un dispositivo mágico que puede convertir datos en soluciones perfectas e\ninmediatas, más bien debe considerarse como una extensión de los procedimientos estadísticos que venimos\nutilizando desde hace décadas. Teniendo en cuenta la gran cantidad de información a la que un médico tiene\nacceso y probablemente tendrá que analizar, una decisión clínica puede ser una tarea abrumadora.\nLa calidad de los resultados que puede darnos un algoritmo depende de la cantidad y calidad de los\ndatos con los que alimentamos nuestro sistema, por lo que el sistema de generación y recolección de datos\nes estratégico para resultados robustos y válidos. Esto es especialmente cierto en el cuidado de la salud\nya que estos algoritmos tienen el potencial de afectar la vida de millones de pacientes. De seguro, el deep\nlearning no sustituirá a los médicos en el futuro cercano. Pero al eliminar gran parte del trabajo aburrido\ny la memorización, facilitarán a los médicos a enfocarse en el cuidado de los pacientes y a tomar decisiones\nPDF generado a partir de XML-JATS4R por Redalyc\nProyecto académico sin fines de lucro, desarrollado bajo la iniciativa de acceso abierto 606\nVíctor Arias, et al. Una introducción a las aplicaciones de la inteligencia artificial en Medicina...\ndentro de un contexto de miles de resultados en el ámbito clínico que forman parte de toda nuestra evidencia\ncientífica acumulada en cientos de años de investigación.\nREFERENCIAS\n1. DiCarlo JJ, Zoccolan D, Rust NC. How does the brain solve visual object recognition? Neuron. el 9 de febrero de\n2012;73(3):415–34.\n2. Wan J, Wang D, Hoi SCH, Wu P, Zhu J, Zhang Y, et al. Deep Learning for Content-Based Image Retrieval: A\nComprehensive Study. En: Proceedings of the 22Nd ACM International Conference on Multimedia [Internet].\nNew York, NY, USA: ACM; 2014 [citado el 18 de octubre de 2017]. p. 157–166. (MM ’14). Disponible en: h\nttp://doi.acm.org/10.1145/2647868.2654948\n3. Nilsson F. Intelligent network video: understanding modern video surveillance systems. Boca Raton: CRC Press;\n2009. 389 p.\n4. Leuba G, Krasik R. Changes in volume, surface estimate, three-dimensional shape and total number of neurons\nof the human primary visual cortex from midgestation until old age. Anat Embryol (Berl). el 1 de octubre de\n1994;190(4):351–66.\n5. Hof RD. Is Artificial Intelligence Finally Coming into Its Own? [Internet]. MIT Technology Review. [citado el 23\nde octubre de 2017]. Disponible en: https://www.technologyreview.com/s/513696/deep-learning/\n6. Esteva A, Kuprel B, Novoa RA, Ko J, Swetter SM, Blau HM, et al. Dermatologist-level classification of skin cancer\nwith deep neural networks. Nature. el 2 de febrero de 2017;542(7639):115–8.\n7. Brouillette M. AI diagnostics are coming [Internet]. MIT Technology Review. [citado el 23 de octubre de 2017].\nDisponible en: https://www.technologyreview.com/s/604271/deep-learning-is-a-black-box-but-health-care-w\nont-mind/\n8. Eastwood G. How deep learning is transforming healthcare [Internet]. Network World. 2017 [citado el 23 de\noctubre de 2017]. Disponible en: https://www.networkworld.com/article/3183745/health/how-deep-learnin\ng-is-transforming-healthcare.html\n9. Suk H-I. An Introduction to Neural Networks and Deep Learning. En: Deep Learning for Medical Image Analysis\n[Internet]. Elsevier; 2017 [citado el 13 de agosto de 2017]. p. 3–24. Disponible en: http://linkinghub.elsevier.\ncom/retrieve/pii/B978012810408800002X\n10. Rosenblatt F. e perceptron: a probabilistic model for information storage and organization in the brain. Psychol\nRev. noviembre de 1958;65(6):386–408.\n11. McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. Bull Math Biophys. el 1 de\ndiciembre de 1943;5(4):115–33.\n12. Minsky M, Papert S. Perceptrons. Oxford, England: M.I.T. Press; 1969.\n13. Hornik K, Stinchcombe M, White H. Multilayer feedforward networks are universal approximators. Neural Netw.\n1989;2(5):359–66.\n14. Linnainmaa S. Taylor expansion of the accumulated rounding error. BIT Numer Math. el 1 de junio de\n1976;16(2):146–60.\n15. Werbos PJ. Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Sciences. Harvard\nUniversity; 1975.906 p.\n16. Rumelhart DE, Hinton GE, Williams RJ. Learning representations by back-propagating errors. Nature. el 9 de\noctubre de 1986;323(6088):533–6.\n17. Rumelhart DE, Hinton GE, Williams RJ. Learning Internal Representations by Error Propagation. 1985 sep.\n18. Bengio Y. Learning Deep Architectures for AI. Found Trends® Mach Learn. 2009;2(1):1–127.\n19. Bay H, Ess A, Tuytelaars T, Van Gool L. Speeded-Up Robust Features (SURF). Comput Vis Image Underst. el\n1 de junio de 2008;110(3):346–59.\nPDF generado a partir de XML-JATS4R por Redalyc\nProyecto académico sin fines de lucro, desarrollado bajo la iniciativa de acceso abierto 607\nRevista Latinoamericana de Hipertensión, 2019, vol. 14, núm. 5, ISSN: 1856-4550\n20. Zhou H, Yuan Y, Shi C. Object tracking using SIFT features and mean shi. Comput Vis Image Underst. el 1 de\nmarzo de 2009;113(3):345–52.\n21. Dalal N, Triggs B. Histograms of oriented gradients for human detection. En: Computer Vision and Pattern\nRecognition, 2005 CVPR 2005 IEEE Computer Society Conference on [Internet]. IEEE; 2005 [citado el 11 de\nmayo de 2017]. p. 886–893. Disponible en: http://ieeexplore.ieee.org/abstract/document/1467360/\n22. LeCun Y, Boser B, Denker JS, Henderson D, Howard RE, Hubbard W, et al. Backpropagation Applied to\nHandwritten Zip Code Recognition. Neural Comput. diciembre de 1989;1(4):541–51.\n23. Hubel DH, Wiesel TN. Receptive fields and functional architecture in two nonstriate visual areas (18 and 19) of\nthe cat. J Neurophysiol. 1965;28(2):229–289.\n24. Lecun Y, Bottou L, Bengio Y, Haffner P. Gradient-based learning applied to document recognition. Proc IEEE.\nnoviembre de 1998;86(11):2278–324.\n25. Waibel A, Hanazawa T, Hinton G, Shikano K, Lang KJ. Phoneme recognition using time-delay neural networks.\nIEEE Trans Acoust Speech Signal Process. marzo de 1989;37(3):328–39.\n26. Werbos PJ. Backpropagation through time: what it does and how to do it. Proc IEEE. octubre de\n1990;78(10):1550–60.\n27. Bengio Y, Simard P, Frasconi P. Learning long-term dependencies with gradient descent is difficult. IEEE Trans\nNeural Netw. marzo de 1994;5(2):157–66.\n28. Schwarz G. Estimating the Dimension of a Model. Ann Stat. marzo de 1978;6(2):461–4.\n29. Schmidhuber J. Deep Learning in Neural Networks: An Overview. Neural Netw. enero de 2015;61:85–117.\n30. Bengio Y. A connectionist approach to speech recognition. Int J Pattern Recognit Artif Intell. el 1 de agosto de\n1993;07(04):647–67.\n31. Hochreiter S. {Untersuchungen zu dynamischen neuronalen Netzen. Diploma thesis, Institut f\\\\\"{u}r Informatik,\nLehrstuhl Prof. Brauer, Technische Universit\\\\\"{a}t M\\\\\"{u}nchen}. 1991;\n32. Hochreiter S, Schmidhuber J. Long Short-Term Memory. Neural Comput. el 1 de noviembre de 1997;9(8):1735–\n80.\n33. LeCun Y, Jackel LD, Bottou L, Brunot A, Cortes C, Denker JS, et al. Comparison of learning algorithms for\nhandwritten digit recognition. En: International conference on artificial neural networks [Internet]. Perth,\nAustralia; 1995 [citado el 2 de mayo de 2017]. p. 53–60. Disponible en: https://pdfs.semanticscholar.org/d50\nd/ce749321301f0104689f2dc582303a83be65.pdf\n34. Hinton GE, Osindero S, Teh Y-W. A Fast Learning Algorithm for Deep Belief Nets. Neural Comput. el 17 de\nmayo de 2006;18(7):1527–54.\n35. DL4J. A Beginner’s Tutorial for Restricted Boltzmann Machines - Deeplearning4j: Open-source, Distributed\nDeep Learning for the JVM [Internet]. [citado el 14 de agosto de 2017]. Disponible en: https://deeplearning4\nj.org/restrictedboltzmannmachine\n36. Salakhutdinov R. Learning deep generative models [Internet]. University of Toronto; 2009 [citado el 14 de agosto\nde 2017]. Disponible en: http://www.cs.toronto.edu/~rsalakhu/papers/Russ_thesis.pdf\n37. Kullback S, Leibler RA. On Information and Sufficiency. Ann Math Stat. 1951;22(1):79–86.\n38. Hinton GE. Training Products of Experts by Minimizing Contrastive Divergence. Neural Comput. el 1 de agosto\nde 2002;14(8):1771–800.\n39. Bengio Y, Lamblin P, Popovici D, Larochelle H, others. Greedy layer-wise training of deep networks. Adv Neural\nInf Process Syst. 2007;19:153.\n40. Raina R, Madhavan A, Ng AY. Large-scale Deep Unsupervised Learning Using Graphics Processors. En:\nProceedings of the 26th Annual International Conference on Machine Learning [Internet]. New York, NY,\nUSA: ACM; 2009 [citado el 2 de mayo de 2017]. p. 873–880. (ICML ’09). Disponible en: http://doi.acm.or\ng/10.1145/1553374.1553486\n41. Srivastava N, Hinton GE, Krizhevsky A, Sutskever I, Salakhutdinov R. Dropout: a simple way to prevent neural\nnetworks from overfitting. J Mach Learn Res. 2014;15(1):1929–1958.\nPDF generado a partir de XML-JATS4R por Redalyc\nProyecto académico sin fines de lucro, desarrollado bajo la iniciativa de acceso abierto 608\nVíctor Arias, et al. Una introducción a las aplicaciones de la inteligencia artificial en Medicina...\n42. Jarrett K, Kavukcuoglu K, LeCun Y, others. What is the best multi-stage architecture for object recognition? En:\nComputer Vision, 2009 IEEE 12th International Conference on [Internet]. IEEE; 2009 [citado el 13 de mayo\nde 2017]. p.2146–2153. Disponible en: http://ieeexplore.ieee.org/abstract/document/5459469/\n43. Dahl GE, Sainath TN, Hinton GE. Improving deep neural networks for LVCSR using rectified linear units and\ndropout. En: 2013 IEEE International Conference on Acoustics, Speech and Signal Processing. 2013. p. 8609–\n13.\n44. Nair V, Hinton GE. Rectified linear units improve restricted boltzmann machines. En: Proceedings of the 27th\ninternational conference on machine learning (ICML-10) [Internet]. 2010 [citado el 13 de mayo de 2017]. p.\n807–814. Disponible en: http://machinelearning.wustl.edu/mlpapers/paper_files/icml2010_NairH10.pdf\n45. Glorot X. Apprentissage des réseaux de neurones profonds et applications en traitement automatique de la langue\nnaturelle. 2015 [citado el 13 de mayo de 2017]; Disponible en: https://papyrus.bib.umontreal.ca/xmlui/hand\nle/1866/11989\n46. Krizhevsky A, Sutskever I, Hinton GE. ImageNet Classification with Deep Convolutional Neural Networks. En:\nPereira F, Burges CJC, Bottou L, Weinberger KQ, editores. Advances in Neural Information Processing Systems\n25 [Internet]. Curran Associates, Inc.; 2012 [citado el 13 de mayo de 2017]. p. 1097–1105. Disponible en: htt\np://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\n47. Channin D. Deep Learning in Healthcare: Challenges and Opportunities [Internet]. e Mission. 2016 [citado\nel 14 de mayo de 2017]. Disponible en: https://themission.co/deep-learning-in-healthcare-challenges-and-opp\nortunities-d2eee7e2545\n48. Leaper DJ, Horrocks JC, Staniland JR, de Dombal FT. Computer-Assisted Diagnosis of Abdominal Pain using\n“Estimates” Provided by Clinicians. Br Med J. el 11 de noviembre de 1972;4(5836):350–4.\n49. Reaz MBI, Hussain MS, Mohd-Yasin F. Techniques of EMG signal analysis: detection, processing, classification\nand applications. Biol Proced Online. diciembre de 2006;8(1):11–35.\n50. Ristevski B, Chen M. Big Data Analytics in Medicine and Healthcare. J Integr Bioinforma [Internet]. el 25 de\nseptiembre de 2018 [citado el 2 de agosto de 2019];15(3). Disponible en: http://www.degruyter.com/view/j/j\nib.2018.15.issue-3/jib-2017-0030/jib-2017-0030.xml\n51. Salazar J, Espinoza C, Mindiola A, Bermudez V. Data Mining and Endocrine Diseases: A New Way to Classify?\nArch Med Res. abril de 2018;49(3):213–5.\n52. Gruber K. Is the future of medical diagnosis in computer algorithms? Lancet Digit Health. mayo de 2019;1(1):e15–\n53. Miotto R, Li L, Kidd BA, Dudley JT. Deep Patient: An Unsupervised Representation to Predict the Future of\nPatients from the Electronic Health Records. Sci Rep. el 17 de mayo de 2016;6:26094.\n54. Xiong HY, Alipanahi B, Lee LJ, Bretschneider H, Merico D, Yuen RKC, et al. e human splicing code reveals\nnew insights into the genetic determinants of disease. Science. el 9 de enero de 2015;347(6218):1254806.\n55. Gawehn E, Hiss JA, Schneider G. Deep Learning in Drug Discovery. Mol Inform. el 1 de enero de 2016;35(1):3–\n14.\n56. Cao C, Liu F, Tan H, Song D, Shu W, Li W, et al. Deep Learning and Its Applications in Biomedicine. Genomics\nProteomics Bioinformatics. 2018; 16(1): 17–32.\n57. Shen D, Wu G, Suk HI. Deep Learning in Medical Image Analysis. Annu Rev Biomed Eng. 2017;19:221-248.\n58. Klann JG, Szolovits P. An intelligent listening framework for capturing encounter notes from a doctor-patient\ndialog. BMC Med Inform Decis Mak. 2009; 9(Suppl 1): S3.\n59. Pang S, Du A, Orgun MA, Yu Z. A novel fused convolutional neural network for biomedical image classification.\nMed Biol Eng Comput. 2019;57(1):107-121.\nPDF generado a partir de XML-JATS4R por Redalyc\nProyecto académico sin fines de lucro, desarrollado bajo la iniciativa de acceso abierto 609"}
{"id": "polipos_ia", "filename": "polipos_ia.pdf", "title": "Revista Colombiana de Gastroenterologia", "body": "Revista Colombiana de Gastroenterologia\nISSN: 0120-9957\nAsociación Colombiana de Gastroenterología\nGómez-Zuleta, Martín Alonso; Cano-Rosales, Diego Fernando; Bravo-Higuera,\nDiego Fernando; Ruano-Balseca, Josué André; Romero-Castro, Eduardo\nDetección automática de pólipos colorrectales con técnicas de inteligencia artificial\nRevista Colombiana de Gastroenterologia, vol. 36, núm. 1, 2021, pp. 7-17\nAsociación Colombiana de Gastroenterología\nDOI: https://doi.org/10.22516/25007440.471\nDisponible en: https://www.redalyc.org/articulo.oa?id=337766864003\nCómo citar el artículo\nNúmero completo Sistema de Información Científica Redalyc\nMás información del artículo Red de Revistas Científicas de América Latina y el Caribe, España y Portugal\nPágina de la revista en redalyc.org Proyecto académico sin fines de lucro, desarrollado bajo la iniciativa de acceso\nabierto\nDOI: https://doi.org/10.22516/25007440.471 Trabajos originales\nDetección automática de pólipos colorrectales con\ntécnicas de inteligencia artificial\nArtificial intelligence techniques for the automatic detection of colorectal\npolyps\nMartín Alonso Gómez-Zuleta,1 Diego Fernando Cano-Rosales,2* Diego Fernando Bravo-Higuera, MSc,3\nJosué André Ruano-Balseca, MSc,4 Eduardo Romero-Castro, PhD.5\nResumen\nACCESO ABIERTO\nEl cáncer colorrectal (CCR) es uno de los tumores malignos con mayor prevalencia en Colombia y el mundo.\nCitación: Estas neoplasias se originan en lesiones adenomatosas o pólipos que deben resecarse para prevenir la\nGómez-Zuleta MA, Cano-Rosales DF, Bravo- enfermedad, lo cual se puede realizar con una colonoscopia. Se ha reportado que durante una colonoscopia\nHiguera DF, Ruano-Balseca JA, Romero-Castro se detectan pólipos en el 40 % de los hombres y en el 30 % de las mujeres (hiperplásicos, adenomatosos,\nE. Detección automática de pólipos colorrectales\ncon técnicas de inteligencia artificial. Rev Colomb serrados, entre otros), y, en promedio, un 25 % de pólipos adenomatosos (principal indicador de calidad en\nGastroenterol. 2021;36(1):7-17. https://doi. colonoscopia). Sin embargo, estas lesiones no son fáciles de observar por la multiplicidad de puntos ciegos\norg/10.22516/25007440.471 en el colon y por el error humano asociado con el examen. Diferentes investigaciones han reportado que\n............................................................................ alrededor del 25 % de pólipos colorrectales no son detectados o se pasan por alto durante la colonoscopia\n1 Médico Internista y Gastroenterólogo. Unidad y, como consecuencia, el paciente puede tener un cáncer de intervalo. Estas cifras muestran la necesidad\nde Gastroenterología y Ecoendoscopia (UGEC). de contar con un segundo observador (sistema de inteligencia artificial) que reduzca al mínimo la posibilidad\nHospital Universitario Nacional. Profesor\nde no detectar estos pólipos y, de este modo, sea posible prevenir al máximo el cáncer de colon. Objetivo:\nasociado de Medicina, Universidad Nacional de\nColombia. crear un método computacional para la detección automática de pólipos colorrectales usando inteligencia\n2 Médico Internista. Fellow de Gastroenterología, artificial en videos grabados de procedimientos reales de colonoscopia. Metodología: se usaron bases de\nUniversidad Nacional de Colombia. Hospital datos públicas con pólipos colorrectales y una colección de datos construida en un Hospital Universitario.\nUniversitario Nacional.\n3 Magister en Ingeniería Biomédica. Inicialmente, se normalizan todos los cuadros de los videos para disminuir la alta variabilidad entre bases\nUniversidad Militar Nueva Granada. Docente de datos. Posteriormente, la tarea de detección de pólipos se hace con un método de aprendizaje profundo\ncátedra. Universidad Nacional de Colombia. usando una red neuronal convolucional. Esta red se inicia con pesos aprendidos en millones de imágenes na-\nBogotá D. C., Colombia.\n4 Magister en Ingeniería Biomédica, Ingeniero turales de la base de datos ImageNet. Los pesos de la red se actualizan usando imágenes de colonoscopia,\nBiomédico, Estudiante de Doctorado en siguiendo la técnica de ajuste fino. Finalmente, la detección de pólipos se realiza asignando a cada cuadro\nIngeniería – Sistemas y computación. una probabilidad de contener un pólipo y determinando el umbral que define cuando el pólipo se encuentra\nUniversidad Nacional de Colombia. Bogotá\npresente en un cuadro. Resultados: este enfoque fue entrenado y evaluado con 1875 casos recopilados\nD. C., Colombia.\n5 Doctor en Ciencias Biomédicas, Magister en de 5 bases de datos públicas y de la construida en el hospital universitario, que suman aproximadamente\nIngeniería Eléctrica, Médico cirujano. Profesor 123 046 cuadros. Los resultados obtenidos se compararon con las marcaciones de diferentes expertos en\ntitular. Universidad Nacional de Colombia.\ncolonoscopia y se obtuvo 0,77 de exactitud, 0,89 de sensibilidad, 0,71 de especificidad y una curva ROC (re-\nBogotá D. C., Colombia.\nceiver operating characteristic) de 0,87. Conclusión: este método logra detectar pólipos de manera sobresa-\n*Correspondencia: liente, superando la alta variabilidad dada por los distintos tipos de lesiones, condiciones diferentes de la luz\nDiego Fernando Cano-Rosales.\ndel colon (asas, pliegues o retracciones) con una sensibilidad muy alta, comparada con un gastroenterólogo\ndfcanor@unal.edu.co\nexperimentado, lo que podría hacer que se disminuya el error humano, el cual es uno de los principales\n............................................................................\nfactores que hacen que no se detecte o se escapen los pólipos durante un examen de colonoscopia.\nFecha recibido: 24/10/19\nFecha aceptado: 11/11/20\nPalabras clave\nColonoscopia, cáncer colorrectal, pólipos, detección, inteligencia artificial.\n© 2021 Asociación Colombiana de Gastroenterología 7\nAbstract\nColorectal cancer (CRC) is one of the most prevalent malignant tumors worldwide. These neoplasms originate\nfrom adenomatous lesions or polyps that must be resected to prevent the development of the disease, and\nthat can be done through a colonoscopy. Polyps are reported during colonoscopy in 40% of men and 30% of\nwomen (hyperplastic, adenomatous, serrated, among others), and, on average 25% are adenomatous polyps\n(the main indicator of quality in colonoscopy). However, these lesions are not easy to visualize because of the\nmultiplicity of blind spots in the colon and human errors associated with the performance of the procedure.\nSeveral research works have reported that about 25% of colorectal polyps are overlooked or undetected\nduring colonoscopy, and as a result, the patient may have interval cancer. These figures show the need\nfor a second observer (artificial intelligence system) to reduce the possibility of not detecting polyps and\nprevent colon cancer as much as possible. Objective: To create a computational method for the automatic\ndetection of colorectal polyps using artificial intelligence using recorded videos of colonoscopy procedures.\nMethodology: Public databases of colorectal polyps and a data collection constructed in a university hospital\nwere used. Initially, all the frames in the videos were normalized to reduce the high variability between databa-\nses. Subsequently, polyps were detected using a deep learning method with a convolutional neural network.\nThis network starts with weights learned from millions of natural images taken from the ImageNET database.\nNetwork weights are updated using colonoscopy images, following the fine-tuning technique. Finally, polyps\nare detected by assigning each box a probability of polyp presence and determining the threshold that defines\nwhen the polyp is present in a box. Results: This approach was trained and evaluated with 1 875 cases\ncollected from 5 public databases and the one built in the university hospital, which total approximately 123\n046 frames. The results obtained were compared with the markings of different experts in colonoscopy, ob-\ntaining 0.77 accuracy, 0.89 sensitivity, 0.71 specificity, and a receiver operating characteristic curve of 0.87.\nConclusion: This method detected polyps in an outstanding way, overcoming the high variability caused by\nthe types of lesions and bowel lumen condition (loops, folds or retractions) and obtaining a very high sensitivity\ncompared with an experienced gastroenterologist. This may help reduce the incidence of human error, as it is\none of the main factors that cause polyps to not be detected or overlooked during a colonoscopy.\nKeywords\nColonoscopy, Colorectal cancer, Polyps, Detection, Artificial intelligence.\nINTRODUCCIÓN una tasa del 92 % (5); por esta razón, es de gran importancia\ndetectar el tumor en estadios tempranos o, más aún, detec-\nEl cáncer colorrectal (CCR) es el tercer cáncer más fre- tar el pólipo en estado adenomatoso (premaligno), con lo\ncuente en el mundo y la segunda causa de muerte por cual se previene la enfermedad. Se sabe que con las técnicas\ncáncer. En Colombia es la cuarta neoplasia más frecuente de tamización disponibles (sangre oculta, colonoscopia), el\nen hombres y mujeres, con tasas de incidencia que aumen- CCR es altamente prevenible en más del 90 % de los casos.\ntan cada año (1, 2). Muchos estudios concluyen que la Múltiples trabajos han demostrado que la colonoscopia\ntamización del CCR es costo-efectiva en población de es el examen de elección para la prevención y detección\nriesgo medio (población sin antecedentes familiares y sin temprana del CCR porque, como se mencionó previa-\nun historial médico que muestre predisposición). Se sabe mente, es capaz de detectar el origen principal del CCR\nque la edad (≥ 50 años), los hábitos alimentarios y el tabaco como son los pólipos adenomatosos (6-9).\nson factores de riesgo que aumentan la incidencia de pade- Además de detectar el cáncer en estados tempranos,\ncer esta enfermedad. En la población general, el riesgo es el cual si se trata a tiempo es completamente curable, la\ndel 5 %-6 % y esta incidencia aumenta de forma sustancial a detección de pólipos es un indicador de calidad en la colo-\npartir de los 50 años, por lo cual se considera que las perso- noscopia y se considera que durante el examen se encuen-\nnas de 50 años o más son población en riesgo medio, para tren pólipos adenomatosos (los cuales tienen alto riesgo de\nla cual se debería iniciar un programa de tamización (3, 4). cáncer) en un 20 % de mujeres y en un 30 % de hombres;\nEn cuanto al grado de supervivencia en los pacientes con es decir que, en promedio, se deberían encontrar pólipos\nCCR, está directamente relacionado con la extensión de adenomatosos en un 25 % de todas las colonoscopias que\nla enfermedad en el momento del diagnóstico. Los indivi- se realizan. Infortunadamente, diferentes estudios han\nduos diagnosticados en estado avanzado tienen una tasa de reportado que alrededor del 26 % de los pólipos que están\nsupervivencia del 7 % a los 5 años, mientras que para suje- presentes en una colonoscopia no se detectan, una tasa\ntos con CCR detectado en un estado inicial se ha reportado de error muy alta explicada básicamente por dos factores:\n8 Rev Colomb Gastroenterol. 2021;36(1):7-17. https://doi.org/10.22516/25007440.471 Trabajos originales\nla cantidad de puntos ciegos durante una colonoscopia clínicas específicas; en particular, el dispositivo de captura,\n(pólipos ubicados detrás de los pliegues, asas del colon, la el protocolo de exploración realizado por el experto y la\npreparación, entre otros) y el error humano (se pasaron por extracción de las secuencias con lesiones fácilmente visuali-\nalto) asociado con el procedimiento (10-12). Se han reali- zables. Aunque se han presentado varios avances, aún existe\nzado múltiples trabajos que buscan atacar estos dos factores el reto de formular modelos generalizables para detectar\npara disminuir esta tasa de pólipos perdidos al máximo, es lesiones de manera precisa, independientemente del tipo de\nasí como se han diseñado accesorios que permiten encon- lesión, forma de exploración del experto o de la unidad de\ntrar los pólipos ocultos detrás de los pliegues como son Cap, colonoscopia usada.\nEndocuff o incluso un miniendoscopio denominado tercer El principal objetivo del presente trabajo es crear una\nojo, que busca aplanar los pliegues o ver detrás de ellos. estrategia automática de detección de pólipos colorrec-\nAdicionalmente, recientemente se ha considerado que el tales con el propósito de construir un segundo lector que\nfactor asociado con el error humano es al menos mitigable soporte el proceso de exploración del colon y de disminuir\ncon la introducción de segundos lectores (computadores), el número de lesiones no detectadas durante una colonos-\nun escenario en el cual la tecnología y la inteligencia arti- copia. En este documento se presenta una estrategia de\nficial empiezan a mostrar resultados que pueden mejorar clasificación automática de pólipos en secuencias de videos\ndrásticamente la tasa de detección de los pólipos y permitir de colonoscopia. Esta investigación se apoya en un algo-\nbajar el número de pólipos no detectados en una unidad de ritmo de aprendizaje profundo y evalúa diferentes arqui-\ngastroenterología. tecturas de redes convolucionales. Este artículo está orga-\nEl desarrollo de estrategias computacionales para la nizado de la siguiente manera: inicialmente, se presenta\nextracción de patrones y la detección automática de pólipos la metodología para la detección automática de pólipos;\ncolorrectales en videos de colonoscopia es un problema luego, se describen las consideraciones éticas alrededor de\nmuy complejo. Los videos de una colonoscopia se registran este trabajo; posteriormente, se muestra la configuración\nen medio de una gran cantidad de fuentes de ruido que experimental junto con los resultados del método detec-\nfácilmente ocultan lesiones; por ejemplo, los brillos en la tando pólipos comparados con las anotaciones de un\npared intestinal producidos por la fuente de luz o reflexión experto; después, se presenta la discusión de este trabajo; y,\nespecular, la motilidad de los órganos y la secreción intes- finalmente, se encuentran las conclusiones y trabajo futuro.\ntinal que ocluyen el campo de visión del colonoscopio, y la\nexperiencia del especialista que influye en la suavidad de la METODOLOGÍA\nexploración del colon. Actualmente, varias estrategias han\nabordado este reto como una tarea de clasificación, utili- Este trabajo presenta una metodología de aprendizaje\nzando técnicas automáticas de aprendizaje de máquina. profundo para modelar la alta variabilidad en un procedi-\nPor una parte, algunos autores han intentado una selección miento de colonoscopia, con el propósito de realizar una\nde características de bajo nivel para obtener límites de detección automática de pólipos en procedimientos de\npólipos candidatos. Bernal y colaboradores (13) presenta- colonoscopia. Esta tarea se divide en dos etapas: entrena-\nron un modelo de apariencia de pólipos que caracteriza los miento y clasificación. En primer lugar, se realiza un pre-\nvalles de los pólipos como límites cóncavos y continuos. procesamiento cuadro a cuadro, común para las dos eta-\nEsta caracterización se usa para entrenar un clasificador que pas. Después, se entrena una red neuronal convolucional\nen un conjunto de prueba (test) obtuvo 0,89 de sensibilidad usando una gran cantidad de imágenes de colonoscopia\nen la tarea de detección de pólipos. Shin y colaboradores anotadas por un gastroenterólogo experto en colonoscopia\n(14) presentaron una estrategia basada en una clasificación (con alrededor de 20 años de experiencia y más de 50 mil\npor parches, usando una combinación de características de colonoscopias realizadas) en dos clases: clase negativa o no\nforma y color, y obtuvieron una sensibilidad de 0,86. Por contiene pólipo, y clase positiva o contiene pólipo. El modelo\notra parte, varios trabajos han utilizado redes neuronales obtenido del proceso de aprendizaje es utilizado para clasi-\nconvolucionales (CNN) profundas, un conjunto de algo- ficar imágenes nuevas (o no usadas en el proceso de entre-\nritmos agrupados bajo el término de aprendizaje profundo. namiento) como perteneciente a alguna de las dos clases. El\nUrban y colaboradores (15) presentaron una red convolu- flujo de este trabajo se visualiza en la Figura 1 y se explica\ncional que detecta pólipos de diferentes tamaños en tiempo a continuación.\nreal con una sensibilidad de 0,95. Sin embargo, Taha y cola-\nboradores (16) analizaron algunas de las limitaciones de PROTOCOLO DE ADQUISICIÓN Y PREPROCESAMIENTO\nestos trabajos, una de ellas es el hecho de que estos métodos\nrequieren una gran cantidad de datos para ser entrenados. Para disminuir el efecto de las numerosas fuentes de ruido\nAdemás, estas bases de datos son adquiridas en condiciones en el proceso de adquisición de diferentes colonoscopios\nDetección automática de pólipos colorrectales con técnicas de inteligencia artificial 9\nBase de datos de E\nentrenamiento\nCuadros con\nCuadros con pólipos\npólipos\nCuadros sin\nAnotación pólipos\ngastroenterólogo\nCuadros sin D\npólipos\nA B\nFigura 1. Flujo del método propuesto para detectar pólipos automáticamente. Primero, se consolidó una base de datos anotada cuadro a cuadro de\nvideos de colonoscopia (A). Cada uno de estos cuadros son preprocesados (B) para alimentar unos modelos basados en CNN (C). Este modelo se\nentrena con un ajuste fino de unos pesos preentrenados con millones de imágenes naturales (D). Con la red entrenada, se evalúa su rendimiento para\ndetectar pólipos (H) con una base de datos de prueba (F) y se comparan los resultados obtenidos con las anotaciones de un experto (G).\ny las condiciones fisiológicas de colon y el recto, es nece- se finaliza con una capa de activación (Figura 1 C, círculos\nsario realizar un preprocesamiento cuadro por cuadro rojos), en la cual se normalizan las probabilidades obteni-\ndel video. Primero, se normaliza cada cuadro con media das y se logra la clasificación binaria deseada. La función de\n0 y desviación estándar (DE) de 1, con el fin de que las estos bloques es:\ncaracterísticas extraídas entre cuadros sean comparables. • Capas convolucionales (convolutional layers): identifica\nLuego, dependiendo del dispositivo de captura, los cua- las características locales en toda la imagen como patro-\ndros presentan distintas resoluciones espaciales, por lo cual nes de forma, bordes y textura, vitales en la descripción\ncada cuadro es escalado recortado a 300 x 300 pixeles, de de pólipos. Esta capa conecta un subconjunto de\nmanera que todos tengan la misma malla de captura. pixeles vecinos de la imagen o neuronas con todos los\nnodos de la primera capa convolucional. Una de estas\nARQUITECTURA DE LAS CNN capas o kernel convolucional se distingue por los pesos\nespecíficos de cada nodo; al ser operado sobre una\nLa unidad principal de estas arquitecturas es la neurona, región específica de la imagen, proporciona un mapa de\nque proporciona una salida como función de las entradas a característica de la región.\nella. Un arreglo de neuronas forma una capa o bloque y una • Capas de agrupamiento (pooling layers): reduce la\nred está compuesta por varios bloques elementales que se complejidad computacional, que a su vez disminuye el\nordenan de la siguiente manera: varios pares de capas con- tamaño de las características en las capas convoluciona-\nvolucionales (Figura 1 C, cuadro azul) y de agrupamiento les y se obtiene un conjunto jerárquico de los mapas de\n(Figura 1 C, cuadro amarillo) que entregan un vector de características de la imagen.\ncaracterísticas de la imagen, seguidos por un conjunto de • Capas completamente conectadas (fully-connected\ncapas completamente conectadas (Figura 1 C, círculos ver- layers): esta capa conecta cada una de las neuronas de\ndes) que se encargan de calcular la probabilidad de que un la capa previa a cada una de las neuronas en la siguiente\nconjunto de características pertenezca a una cierta clase, y capa. La capa previa es una representación plana o vec-\n10 Rev Colomb Gastroenterol. 2021;36(1):7-17. https://doi.org/10.22516/25007440.471 Trabajos originales\notneimasecorperP\nEntrenamiento por ajuste fino\nRed neuronal convolucional\nInicialización\nPesos preentrenados\nImageNet\nnóicacfiisalC\nDetección de pólipos\nBase de datos de Evaluación\nevaluación Anotación\ngastroenterólogo\ntor de los mapas de características obtenidos. El número colonoscopia tiene aproximadamente 12 000 cuadros por\nde neuronas de la siguiente capa es determinado por el video, por lo cual la disponibilidad de bases de datos con\nnúmero de clases que se requiere clasificar. Finalmente, imágenes anotadas es limitada. Entonces, entrenar con un\nla capa completamente conectada provee una votación número limitado de datos e iniciar los pesos de la red de\npara determinar si una imagen pertenece a una clase manera aleatoria, como se hace generalmente, resulta en un\nespecífica. proceso de entrenamiento fallido. Para evitar este inconve-\n• Función de activación (activation function): normaliza niente, se usan pesos (transfer learning) de redes del mismo\nlas probabilidades obtenidas de las capas completa- tipo, que han sido previamente entrenados para otro pro-\nmente conectadas según una función específica, en las blema de clasificación en imágenes naturales, con bases de\nque se obtiene una probabilidad de 0 a 1. datos que contienen grandes cantidades de imágenes ano-\ntadas. La razón por la cual se hace de esta manera es que,\nUna arquitectura en particular se compone por un arreglo aun cuando las imágenes naturales y las de colonoscopia\nde módulos que contienen diferentes configuraciones y sean diferentes, su estructura estadística es similar y, asi-\nórdenes de bloques fundamentales explicados anterior- mismo, la construcción de primitivas que representan los\nmente, y se conoce como gradiente al resultado obtenido objetos. En estas circunstancias, las redes entrenadas para\npor cada neurona. En este trabajo se utilizaron tres arqui- reconocer objetos en imágenes naturales se usan como\ntecturas altamente evaluadas y validadas en el estado del condición inicial para entrenar estas redes en la tarea de\narte: InceptionV3, Vgg16 y ResNet50. A continuación se reconocer pólipos.\ndescribe cada una de ellas. El uso de estos pesos se realiza por medio de un proceso\n• InceptionV3: se compone de 48 capas con 24 millo- llamado ajuste fino (fine tuning), para el cual se toma toda la\nnes de parámetros. En gran parte, estas capas están red preentrenada y se retira la última capa completamente\nagrupadas en 11 módulos, en los cuales se extraen conectada. Esta capa es reemplazada por una nueva, que\ncaracterísticas a múltiples niveles. Cada módulo se tiene el mismo número de neuronas que el número de cla-\ncompone de una configuración determinada de capas ses en la tarea de clasificación (pólipo-no pólipo) y se inicia\nconvolucionales y de agrupamiento, rectificadas por la con los pesos de la red preentrenada. Entonces, primero se\nfunción unidad lineal rectificadora (ReLu). Finaliza con entrena la última capa y, posteriormente, se actualizan los\nuna función de activación llamada exponencial normali- pesos del resto de capas de la red en un proceso iterativo;\nzada (softmax) (17). esta metodología se conoce como propagación hacia atrás.\n• Vgg16: se organiza en 16 capas para un total de 138 000 Cada iteración de este entrenamiento se realiza usando un\nparámetros. 13 de las capas son convolucionales, con cierto número de muestras o lotes (batch) de las imágenes\nuna de agrupamiento (en algunas), 2 capas comple- de entrenamiento. Este proceso termina cuando la red fue\ntamente conectadas y finaliza con una función de entrenada con todas las muestras del conjunto, conocido\nactivación exponencial normalizada. Esta arquitectura como una época (epoch) de entrenamiento. El número de\nse destaca por usar pequeños filtros de tamaño 3 x 3 épocas se determina según la complejidad de las muestras\nen las capas convolucionales. En comparación con la a clasificar. Finalmente, el entrenamiento culmina cuando\nmayoría de arquitecturas, el costo computacional de la probabilidad de una imagen de entrenamiento sea alta y\nesta es menor (18). concuerde con la etiqueta anotada.\n• ResNet50: se compone de 50 capas con 26 millones de\nparámetros. Esta arquitectura se construye bajo el con- DETECCIÓN DE PÓLIPOS\ncepto de redes residuales. Es común que en arquitec-\nturas muy profundas como la mencionada, el gradiente Usando el modelo de la red entrenada, este se aplica a un\npropagado se desvanezca en las últimas capas. Para evi- conjunto de videos de evaluación en el que se clasifica y\ntar esto, ciertas capas son entrenadas con el residuo del asigna una etiqueta: (1) cuadros con y (0) sin presencia de\ngradiente obtenido en esta y el gradiente de una capa pólipos. Sin embargo, hay cuadros con estructuras que se\ndos posiciones antes. Esta arquitectura finaliza con una asemejan a la apariencia de un pólipo, como son las burbu-\nfunción de activación exponencial normalizada (19). jas producidas por los fluidos intestinales. En estos cuadros,\nel modelo presenta un error de clasificación, tomando este\nENTRENAMIENTO POR AJUSTE FINO cuadro como si tuviera una lesión presente. Analizando\ntemporalmente estos errores, es notable que se presentan\nUn alto rendimiento en la clasificación de las clases depende como valores atípicos (de 3 a 10 cuadros) en una ventana\nen su gran mayoría de la cantidad de imágenes anotadas y de tiempo pequeña (60 cuadros o 2 segundos). Por tanto, la\nla forma de iniciar los pesos para entrenar los CNN. Una clasificación realizada por la red es filtrada temporalmente y\nDetección automática de pólipos colorrectales con técnicas de inteligencia artificial 11\ndetermina que, si al menos el 50 % de 60 cuadros contiguos ETISLarib Polyp DB\nson clasificados sin presencia de pólipos, el resto de los cua-\ndros son filtrados y se les asigna una nueva etiqueta, como Presenta 196 imágenes con pólipos cada una anotada por\ncuadros que no contienen pólipo. Finalmente, un pólipo es un experto. Esta base de datos fue utilizada en el conjunto\ndetectado cuando el método propuesto clasifica una ima- de prueba para el evento MICCAI 2015 Sub-Challenge\ngen como cuadro con pólipo presente o clase positiva. on Automatic Polyp Detection Challenge in Colonoscopy\nVideos (22).\nBASES DE DATOS\nThe Kvasir Dataset\nLa construcción de la base de datos en este trabajo tuvo\ncomo propósito capturar la mayor variabilidad de un pro- Es una base de datos que se recopilaron utilizando equi-\ncedimiento de colonoscopia. Para entrenar y evaluar el pos endoscópicos en Vestre Viken Health Trust (VV), en\nenfoque propuesto se reunieron secuencias de diferentes Noruega. Las imágenes son anotadas por uno o más expertos\ncentros de gastroenterología que contienen lesiones poli- médicos de VV y el Registro de Cáncer de Noruega (CRN). El\npoides y no polipoides de tamaños variados (morfología y conjunto de datos consta de las imágenes con una resolución\nubicación en el colon), exploraciones hechas por distintos diferente de 720 x 576 hasta 1920 x 1072 píxeles (20).\nexpertos y equipos de captura. A continuación, se detallan\nestas bases de datos. HU-DB\nASU-Mayo Clinic Colonoscopy Video Database Esta colección fue construida en el Hospital Universitario en\nBogotá, que contiene 253 videos de colonoscopias con un\nEste conjunto se construyó en el Departamento de total de 233 lesiones. Cada cuadro de los videos fue anotado\nGastroenterología de la Clínica Mayo en Arizona, Estados por un experto en colonoscopia con alrededor de 20 años de\nUnidos. Consta de 20 secuencias de colonoscopia, dividi- experiencia y más de 50 000 colonoscopias realizadas.\ndas en 10 con presencia de pólipos y 10 sin presencia de Cada uno de estos videos se capturó a 30 cuadros por\nellos. Las anotaciones fueron realizadas por estudiantes de segundo y a una resolución espacial de 895 x 718, 574 x\ngastroenterología y validadas por un especialista experto. 480 y 583 x 457. En total, se consolidó una base de datos\nEsta colección se ha usado con gran frecuencia en el estado con 1875 casos y un total de 48 573 cuadros con presencia\ndel arte y resalta como la base de datos para el evento “2015 de pólipos y 74 548 cuadros sin presencia de pólipos. Cada\nISBI Grand Challenge on Automatic Polyp Detection in uno de los cuadros de estos videos fue anotado por un\nColonoscopy Videos” (20). experto como positivo si había presencia de pólipo, o nega-\ntivo cuando no había presencia de pólipo. En la Tabla 1\nCVC-ColonDB se resume el número de videos y cuadros por base de datos\nutilizados en este trabajo.\nSe compone de 15 secuencias cortas de diferentes lesiones,\nacumulando un total de 300 cuadros. Las lesiones de esta Tabla 1. Descripción de la cantidad de videos o casos y cuadros de videos\ncolección presentan una alta variabilidad y dificultad de de colonoscopia por cada una de las bases de datos usadas en este trabajo*\ndetección, ya que son bastante similares a las regiones sanas.\nBase de datos Número de videos Cuadros\nCada cuadro fue anotado por un experto gastroenterólogo.\nPólipo No pólipo Pólipo No pólipo\nEsta colección fue construida en el Hospital Clínico de\nBarcelona, España (13). ASU-Mayo 10 10 4683 13481\nCVC-ClinicDB 29 0 612 0\nCVC-ClinicDB\nCVC-ColonDB 15 0 379 0\nETIS 28 0 196 0\nConsiste en 29 secuencias cortas con diferentes lesiones\nque reúnen 612 cuadros anotados por un experto. Esta base Kvasir 1000 500 1000 500\nde datos fue utilizada por el conjunto de entrenamiento HU 233 50 41 703 60 567\ndel evento MICCAI 2015 Sub-Challenge on Automatic Total 1315 560 48 573 74 548\nPolyp Detection Challenge in Colonoscopy Videos.\nEsta colección fue construida en el Hospital Clínico de *La consolidación de varias bases de datos para entrenar y evaluar la\nmetodología propuesta permite abarcar una gran variabilidad de lesiones.\nBarcelona, España (21).\n12 Rev Colomb Gastroenterol. 2021;36(1):7-17. https://doi.org/10.22516/25007440.471 Trabajos originales\nCONSIDERACIONES ÉTICAS problema de clasificación binaria. Este método establece\nuna etiqueta a cada cuadro como clase negativa (cuadro\nEl presente trabajo está acorde a la resolución n.° 008430 de que no contiene pólipo) o clase positiva (cuadro que con-\n1993, que establece las normas científicas, técnicas y admi- tiene pólipo). Para evaluar el rendimiento de este trabajo,\nnistrativas para la investigación en humanos (artículo 11). se compara la etiqueta estimada o predicha con la etiqueta\nEste proyecto se clasifica como investigación con riesgo anotada por el experto. Esta comparación permite calcular\nmínimo, dado que solo se requiere del uso de imágenes la matriz de confusión, que contabiliza lo siguiente:\ndigitales, las cuales se generan a partir de videos de colo- • Verdaderos positivos (true-positives [TP]): es la canti-\nnoscopias anonimizados; es decir, no existe manera alguna dad de cuadros que fueron clasificados correctamente\nde conocer el nombre o la identificación de los sujetos como clase positiva por el modelo.\nincluidos en el estudio. • Verdaderos negativos (true-negatives [TN]): es la canti-\ndad de cuadros que fueron clasificados correctamente\nRESULTADOS como clase negativa por el modelo.\n• Falsos positivos (false-positives [FP]): es la cantidad de\nLas CNN utilizadas en este trabajo son InceptionV3, cuadros que fueron clasificados incorrectamente como\nResnet50 y Vgg16. Las etiquetas asignadas por cada una clase positiva por el modelo.\nde estas redes fueron comparadas con las anotaciones rea- • Falsos negativos (false-negatives [FN]): es la cantidad\nlizadas por los especialistas en cada uno de los cuadros. La de cuadros que fueron clasificados incorrectamente\nsiguiente configuración experimental y la metodología de como clase negativa por el modelo.\nevaluación fueron aplicadas a cada una de las arquitecturas.\nTabla 2. Descripción de la cantidad de secuencias y cuadros escogidos de\nConfiguración experimental cada base de datos para evaluar el desempeño de la metodología propuesta*\nBase de datos Número de videos Cuadros\nLos CNN fueron entrenados previamente con imágenes\nde la base de datos pública ImageNet, esta contiene un Pólipo No pólipo Pólipo No pólipo\naproximado de 14 millones de imágenes naturales. Los\nASU-Mayo 5 2 2124 2553\npesos resultantes son utilizados para iniciar un nuevo pro-\nceso de entrenamiento de cuadros de colonoscopia por CVC-ClinicDB 9 0 191 0\nla metodología de ajuste fino. Este método actualiza los CVC-ColonDB 4 0 145 0\npesos, entrenando la red con la base de datos de colonos-\nETIS 7 0 45 0\ncopia. La actualización de los pesos fue realizada con 120\népocas sobre la totalidad del conjunto de entrenamiento. HU 78 23 21 326 44 460\nCada época entrenaba el modelo tomando un lote de 32 Total 103 25 23 831 47 013\ncuadros hasta abarcar todos los cuadros en su totalidad.\nPara cada una de las redes, el umbral de decisión fue ajus- *Esto corresponde aproximadamente al 30 % de la base datos en total.\ntado manualmente, orientado a mantener un equilibrio\nen el desempeño de clasificación para ambas clases. El Usando la matriz de confusión, se seleccionaron y calcula-\nesquema de entrenamiento fue 70 % de la base de datos ron 4 métricas de clasificación que evalúan el desempeño\npara entrenar y un 30 % para validar respecto al número de del método para clasificar cuadros con (clase positiva) y sin\ncasos; es decir que los datos se separan desde el principio y (clase negativa) pólipo independientemente, y el poder de\nlos datos de entrenamiento, validación y prueba nunca se predicción en ambas clases en general:\nmezclan. En total, las redes fueron entrenadas y validadas • La sensibilidad mide la proporción de cuadros correc-\ncon 213 casos (24 668 cuadros) con pólipos y 36 videos tamente clasificados que contienen pólipos.\n(27 534 cuadros) sin pólipos. La evaluación se realizó con • La especificidad calcula la proporción de cuadros\n103 videos (23 831 cuadros) con pólipos y 25 videos (47 correctamente clasificados que no contienen pólipos.\n013 cuadros) sin pólipos. El detalle de esta colección se • La precisión indica el poder predictivo del método para\npresenta en la Tabla 2. clasificar cuadros con pólipos.\n• La exactitud es la tasa de cuadros clasificados correcta-\nEvaluación cuantitativa mente, según el número total de estos.\nEl enfoque propuesto detecta automáticamente pólipos en Los resultados obtenidos se presentan por cada una de\nvideos de colonoscopia; esta tarea está enmarcada como un las arquitecturas de aprendizaje profundo explicadas en\nDetección automática de pólipos colorrectales con técnicas de inteligencia artificial 13\nla sección de metodología. En la Tabla 3 se presentan los que mejor detectó la clase negativa o cuadros sin pólipos, y\nresultados obtenidos por cada una de las arquitecturas. se obtuvo un 0,81 de especificidad. Para evaluar de manera\nmás detallada el rendimiento de estas arquitecturas, se cons-\nTabla 3. Resultados obtenidos por el método propuesto* truyeron las curvas ROC (receiver operating characteristic)\npor arquitectura. En esta representación se busca analizar\nMétrica InceptionV3 Resnet50 Vgg16 cómo los modelos clasifican las imágenes en términos de\nespecificidad y sensibilidad variando el umbral de decisión\nExactitud 0,81 0,77 0,73\nsobre las probabilidades entregadas por el modelo. Como\nSensibilidad 0,82 0,89 0,81 se puede apreciar en la Figura 2, la arquitectura Resnet50\nsepara mejor las clases independientemente del umbral de\nEspecificidad 0,81 0,71 0,70\ndecisión. Esto indica que esta arquitectura logró generalizar\nPrecisión 0,67 0,59 0,56\nmejor la variabilidad intra- e interclases.\nPuntaje F1 0,74 0,71 0,66\nDISCUSIÓN\nROC (área bajo la curva) 0,85 0,87 0,81\n*En las columnas se especifica la arquitectura en evaluación y en las filas, La detección de los pólipos adenomatosos es el principal\ncada una de las métricas utilizadas. indicador de calidad en colonoscopia, dado que es un\nmarcador fundamental para la detección y prevención del\nPor una parte, aunque la mayoría de estas arquitectu- CCR. En muchos países, la calidad del gastroenterólogo se\nras muestran un rendimiento sobresaliente en la tarea de mide por el número de estos pólipos que detecta en todas\nclasificación, la arquitectura Resnet50 presenta las mejores sus colonoscopias y en promedio gira alrededor de un 25 %\nmétricas en términos de qué tan bien detectó la clase posi- para el experto, pero puede ser tan baja como del 10 %\ntiva o cuadros con pólipos, y se obtuvo un 0,89 de sensi- para el gastroenterólogo inexperto, lo cual lleva a que a este\nbilidad. Por otra parte, la arquitectura InceptionV3 fue la último se le escapen más los adenomas.\nCurva ROC, modelos de aprendizaje profundo\n0,9\n0,8\n0,7\n0,6\n0,5 InceptionV3\nResnet50\n0,4\nVGG16\n0,3\nFigura 2. Curvas ROC para cada una\n0,2 de las arquitecturas evaluadas. La línea\nnaranja corresponde a la curva de la\narquitectura InceptionV3; la línea\n0,1\nazul, a la arquitectura Resnet50; y la\nlínea verde, a la arquitectura Vgg16.\nLa arquitectura Resnet50 presenta un\n0 0,1 0,2 0,3 0,4 0,5 0,6 0,7 0,8 0,9 1\nmejor desempeño, con un área bajo la\ncurva de 0,87.\n14 Rev Colomb Gastroenterol. 2021;36(1):7-17. https://doi.org/10.22516/25007440.471 Trabajos originales\nsovitisop\nsoredadrev\nasaT\nTasa de falsos positivos\nEs así como varios estudios (10-12) reportan que el 26 % estas. Estos trabajos usan metodologías diferentes para\nde los pólipos no se detectan durante las colonoscopias, lo cada tarea, ya que cada una tiene su propio nivel de com-\ncual puede contribuir para que se presenten más casos de plejidad. En general, para detectar cuadros con pólipos se\nCCR. Es así como se presentaron 1,8 millones de nuevos miden relaciones contextuales o globales a nivel de la ima-\ncasos en el mundo para el 2018 (International Agency for gen; mientras que la localización y segmentación analizan a\nResearch on Cancer, 2018) (1). Esta tasa de pérdida se nivel del píxel midiendo relaciones locales.\ndebe a que hay varios factores que afectan una exploración Este trabajo presenta una estrategia robusta para la\nadecuada del colon como la experiencia y el nivel de detección de pólipos, solventada como un problema de\nconcentración (asociado con la fatiga) del experto durante clasificación. Las redes profundas para tareas de clasificación\ntoda una jornada laboral, las condiciones fisiológicas del son métodos que fueron formulados décadas atrás, pero no\ncolon como puntos ciegos en las haustras y la dificultad de habían sido explotadas ya que la potencia de cómputo y la\nubicar el colonoscopio por la motilidad propia del órgano, disponibilidad de bases de datos anotadas era limitada. En\ny la preparación previa del colon por parte del paciente, que los últimos 5 años, el uso de estos modelos ha aumentado\ndetermina qué tan observables son las paredes del colon, drásticamente a causa de desarrollos tecnológicos que per-\nsegún el nivel de limpieza de estas (23). La mayoría de miten una gran cantidad de procesamiento en paralelo y la\nestos factores advierte que la colonoscopia es altamente publicación de bases de datos con millones de imágenes\ndependiente del factor humano, exhibiendo una necesidad como ImageNet. Esto permitió diseñar redes altamente\nde contar con segundos lectores que no se vean afectados complejas y entrenarlas exhaustivamente, de modo que se\npor estos factores. El uso de herramientas computacionales obtuvo un alto rendimiento en tareas de clasificación, ya\npara la detección de pólipos en la práctica clínica ayudaría que es capaz de modelar una alta variabilidad de formas,\na corroborar los hallazgos realizados por el experto y, de colores y texturas. Sin embargo, en el ámbito médico, no se\nmayor importancia, alertar sobre posibles lesiones que dispone de una gran cantidad de datos públicos anotados,\nel experto no detectó. De este modo, estas herramientas por lo que no se contemplaba aplicar estos modelos a pro-\nayudarían a disminuir las tasas de pólipos no detectados y, blemas de detección o clasificación de enfermedades.\npor ende, disminuir la incidencia del CCR. El desarrollo de técnicas de transferencia de aprendizaje\nPara dar soporte al diagnóstico del CCR usando herra- (o transfer learning) proporcionó una solución a la escasez\nmientas por visión de computador, este reto se ha abordado de datos médicos. Los pesos de las redes entrenadas con\nde la siguiente manera: millones de imágenes naturales se utilizaron para iniciar\n• detección, refiriéndose a la clasificación binaria cuadro una nueva red y entrenarla con una cantidad mucho menor\na cuadro de un video en clase positiva (con pólipo) y en de datos diferentes, como imágenes de colonoscopia. Los\nclase negativa (sin pólipo); trabajos del estado del arte que han utilizado este flujo\n• localización, como la delimitación gruesa (por medio demuestran que tiene la capacidad de generalizar adecua-\nde un recuadro) de la lesión sobre una imagen que con- damente la alta variabilidad de cuadros con y sin lesiones\ntiene pólipo; polipoides en imágenes de colonoscopia extraídas de una\n• segmentación, como una delimitación fina de la lesión base de datos en particular. Sin embargo, los diferentes\n(delineando el borde del pólipo). tipos de lesiones y las condiciones fisiológicas típicas del\nintestino grueso no son la única fuente de variabilidad.\nLa detección de pólipos es la primera tarea y principal que Cuanto menor sea la experticia del especialista, los videos\ndebe afrontar el gastroenterólogo. Las tareas posteriores a son propensos a tener una mayor cantidad de cuadros rui-\nla detección (la localización y segmentación) son procesos dosos producidos por oclusiones y movimientos abruptos\nde utilidad para el experto cuando ya ha detectado la lesión del colonoscopio. Adicionalmente, los dispositivos de\ny necesita describirla morfológicamente, tomando como captura varían en las fuentes de luz y los ángulos de visión\nreferencia guías médicas como la Clasificación de París (6). de las cámaras. Por tanto, entrenar y validar con bases de\nEsta clasificación le permite decidir el manejo quirúrgico datos obtenidas de un solo servicio de gastroenterología\nde la enfermedad a corto y largo plazo. Consecuentemente, en específico, como lo hacen los trabajos del estado del\nestas tareas dependen totalmente de qué tan precisa sea la arte (13-15) que han presentado rendimientos sobresa-\ndetección previa; por tanto, la metodología propuesta se lientes, no abarca toda la variabilidad que tiene la tarea de\nenfoca exclusivamente en la tarea principal que requiere el clasificación de imágenes de colonoscopia.\nexperto: obtener cuadros de colonoscopia con presencia Debido a lo anterior, en este trabajo se consolidó un con-\nde lesiones. Además, en el estado del arte, los trabajos que junto de videos de entrenamiento con una alta variabilidad\nhan abordado estas tareas (13-15) describen limitaciones que no se ha presentado en el estado del arte al reunir secuen-\npara presentar un solo flujo abarcando al menos dos de cias de distintas bases de datos. El conjunto usado para entre-\nDetección automática de pólipos colorrectales con técnicas de inteligencia artificial 15\nnar este enfoque contiene: lesiones de distintos tamaños, ser usadas de rutina como segundos lectores en un servicio\nposiciones y formas; procedimientos de colonoscopia y ano- de colonoscopia.\ntaciones realizados por distintos expertos gastroenterólogos; Es notable que estas redes generalizan adecuadamente la\ny videos capturados usando diferentes unidades de colonos- alta variabilidad de los videos de colonoscopia. Los resul-\ncopia. A pesar de dicha variabilidad, este trabajo obtiene una tados obtenidos demuestran que el método propuesto\nsensibilidad de 0,89 y una especificidad de 0,71 en la tarea de puede diferenciar sobresalientemente imágenes con y sin\ndetección de pólipos en secuencias de colonoscopia. presencia de pólipos, independientemente del protocolo\nclínico particular con el que se grabó el video, refiriéndose\nCONCLUSIONES al experto que realiza el procedimiento y el dispositivo de\ncaptura. Este método podría ser útil para disminuir la bre-\nLas metodologías de aprendizaje profundo actualmente cha entre el gastroenterólogo experto y el principiante en la\nson una opción prometedora para ser usadas en tareas de tasa de detección de adenoma.\nclasificación médica. El avance de la tecnología junto al Como trabajo futuro, el enfoque propuesto debe ser\ndiseño y evaluación constante de las redes ha permitido sometido en procedimientos de colonoscopia completo y\nconsolidar un conjunto de métodos y flujos para que ten- evaluar si es posible que sea implementado en tiempo real,\ngan un alto desempeño. Con las redes evaluadas en este además de desarrollar una estrategia que permita no solo\ntrabajo, los resultados obtenidos demuestran que pueden detectar, sino también delimitar la lesión dentro del cuadro.\nREFERENCIAS\n1. Bray F, Ferlay J, Soerjomataram I, Siegel RL, Torre LA, 8. Nagorni A, Bjelakovic G, Petrovic B. Narrow band imaging\nJemal A. Global cancer statistics 2018: GLOBOCAN esti- versus conventional white light colonoscopy for the detec-\nmates of incidence and mortality worldwide for 36 cancers tion of colorectal polyps. Cochrane Database Syst Rev.\nin 185 countries. CA Cancer J Clin. 2018;68(6):394-424. 2012;1:CD008361. http://dx.doi.org/10.1002/14651858.\nhttp://dx.doi.org/10.3322/caac.21492 CD008361.pub2\n2. Data I, Method L. Globocan Colombia 2018. 2018;380:1-2. 9. Jin XF, Chai TH, Shi JW, Yang XC, Sun QY. Meta-analysis\n3. Samadder NJ, Curtin K, Tuohy TM, Pappas L, Boucher K, for evaluating the accuracy of endoscopy with narrow band\nProvenzale D, Rowe KG, Mineau GP, Smith K, Pimentel imaging in detecting colorectal adenomas. J Gastroenterol\nR, Kirchhoff AC, Burt RW. Characteristics of missed or Hepatol. 2012;27(5):882-7. http://dx.doi.org/10.1111/\ninterval colorectal cancer and patient survival: a popula- j.1440-1746.2011.06987.x\ntion-based study. Gastroenterology. 2014;146(4):950-60. 10. Komeda Y, Suzuki N, Sarah M, Thomas-Gibson S, Vance\nhttp://dx.doi.org/10.1053/j.gastro.2014.01.013 M, Fraser C, Patel K, Saunders BP. Factors associated\n4. Kaltenbach T, Sano Y, Friedland S, Soetikno R; with failed polyp retrieval at screening colonoscopy.\nAmerican Gastroenterological Association. American Gastrointest Endosc. 2013;77(3):395-400. http://dx.doi.\nGastroenterological Association (AGA) Institute tech- org/10.1016/j.gie.2012.10.007\nnology assessment on image-enhanced endoscopy. 11. Choi HN, Kim HH, Oh JS, Jang HS, Hwang HS, Kim\nGastroenterology. 2008;134(1):327-40. http://dx.doi. EY, Kwon JG, Jung JT. [Factors influencing the miss\norg/10.1053/j.gastro.2007.10.062 rate of polyps in a tandem colonoscopy study]. Korean\n5. Brown SR, Baraza W, Din S, Riley S. Chromoscopy ver- J Gastroenterol. 2014;64(1):24-30. http://dx.doi.\nsus conventional endoscopy for the detection of polyps org/10.4166/kjg.2014.64.1.24\nin the colon and rectum. Cochrane Database Syst Rev. 12. van Rijn JC, Reitsma JB, Stoker J, Bossuyt PM, van\n2016;4:CD006439. http://dx.doi.org/10.1002/14651858. Deventer SJ, Dekker E. Polyp miss rate determined by tan-\nCD006439.pub4 dem colonoscopy: a systematic review. Am J Gastroenterol.\n6. The Paris endoscopic classification of superficial 2006;101(2):343-50. http://dx.doi.org/10.1111/j.1572-\nneoplastic lesions: esophagus, stomach, and colon: 0241.2006.00390.x\nNovember 30 to December 1, 2002. Gastrointest Endosc. 13. Bernal J, Sánchez J, Vilariño F. Towards automatic\n2003;58(6 Suppl):S3-43. http://dx.doi.org/10.1016/ polyp detection with a polyp appearance model.\ns0016-5107(03)02159-x Pattern Recognition. 2012;45(9):3166-82. https://doi.\n7. Dinesen L, Chua TJ, Kaffes AJ. Meta-analysis of narrow- org/10.1016/j.patcog.2012.03.002\nband imaging versus conventional colonoscopy for ade- 14. Younghak Shin, Balasingham I. Comparison of hand-craft\nnoma detection. Gastrointest Endosc. 2012;75(3):604-11. feature based SVM and CNN based deep learning fra-\nhttp://dx.doi.org/10.1016/j.gie.2011.10.017\n16 Rev Colomb Gastroenterol. 2021;36(1):7-17. https://doi.org/10.22516/25007440.471 Trabajos originales\nmework for automatic polyp classification. Annu Int Conf 20. Tajbakhsh N, Gurudu SR, Liang J. Automated Polyp\nIEEE Eng Med Biol Soc. 2017;2017:3277-3280. http:// Detection in Colonoscopy Videos Using Shape and\ndx.doi.org/10.1109/EMBC.2017.8037556 Context Information. IEEE Trans Med Imaging.\n15. Urban G, Tripathi P, Alkayali T, Mittal M, Jalali F, Karnes 2016;35(2):630-44. http://dx.doi.org/10.1109/\nW, Baldi P. Deep Learning Localizes and Identifies TMI.2015.2487997\nPolyps in Real Time With 96% Accuracy in Screening 21. Bernal J, Sánchez FJ, Fernández-Esparrach G, Gil D,\nColonoscopy. Gastroenterology. 2018;155(4):1069-1078. Rodríguez C, Vilariño F. WM-DOVA maps for accurate\ne8. http://dx.doi.org/10.1053/j.gastro.2018.06.037 polyp highlighting in colonoscopy: Validation vs. saliency\n16. Taha B, Werghi N, Dias J. Automatic Polyp Detection in maps from physicians. Comput Med Imaging Graph.\nEndoscopy Videos: A Survey. Biomed Eng. 2017. http:// 2015;43:99-111. http://dx.doi.org/10.1016/j.compmedi-\ndx.doi.org/10.2316/P.2017.852-031 mag.2015.02.007\n17. Szegedy C, Vanhoucke V, Ioffe S, Shlens J, Wojna Z. 22. Silva J, Histace A, Romain O, Dray X, Granado B. Toward\nRethinking the Inception Architecture for Computer embedded detection of polyps in WCE images for early\nVision. Proc IEEE Comput Soc Conf Comput Vis Pattern diagnosis of colorectal cancer. Int J Comput Assist Radiol\nRecognit. 2016;2818-26. Surg. 2014;9(2):283-93. http://dx.doi.org/10.1007/\n18. Simonyan K, Zisserman A. Very Deep Convolutional s11548-013-0926-3\nNetworks for Large-Scale Image Recognition. ICLR. 23. Freedman JS, Harari DY, Bamji ND, Bodian CA, Kornacki\n2015;1-14. S, Cohen LB, Miller KM, Aisenberg J. The detection\n19. Kaiming H, Xiangyu Z, Shaoqing R, Jian S. Deep residual of premalignant colon polyps during colonoscopy is\nlearning for image recognition. In: Proceedings of the IEEE stable throughout the workday. Gastrointest Endosc.\nconference on computer vision and pattern recognition. 2011;73(6):1197-206. http://dx.doi.org/10.1016/j.\n2016. p. 770-778. gie.2011.01.019\nDetección automática de pólipos colorrectales con técnicas de inteligencia artificial 17"}
{"id": "Redes_Neuronales_Artificiales", "filename": "Redes_Neuronales_Artificiales.pdf", "title": "Redes Neuronales Artificiales", "body": "Redes Neuronales Artificiales\nFernandoIzaurietayCarlosSaavedra\nDepartamentodeFísica,UniversidaddeConcepción,Concepción,Chile\nRESUMEN\nEn esta charla se entrega una descripción de las características principales del funcionamiento de redes\nneuronales artificiales. En primer lugar, se presenta un modelo sencillo de red neuronal y las familias de\nproblemasquepuedensermodeladasporellas. Además, sedescribeesquemassimplesdeentrenamientode\nredesorientadasalreconocimientodepatronesdeinformación. Sepresentaunejemplodeaplicacióndelas\nredesalreconocimientodetexto.\n1. Introducción. por ejemplo, de una persona que quizás ha cambiado de\naspecto(lucedistintoosimplementeenvejeció)enunpaisaje\nLas actividades de investigación desarrolladas en torno al cambiante (que puede contener muchos otros rostros). En\nestudio de redes neuronales artificiales, simplemente redes la actualidad, tareas mucho más simples consumen días de\nneuronales o neuroredes, están motivadas en modelar la trabajo de los computadores más veloces. La plasticidad\nforma de procesamiento de la información en sistemas se percibe también en la capacidad de responder de forma\nnerviosos biológicos. Especialmente, por la forma de correcta frente a un estímulo nunca antes recibido. Esa\nfuncionamiento del cerebro humano, que es completamente capacidad hace que cuando nos presentan por primera vez a\ndistinta al funcionamiento de un computador digital alguien, sepamos automáticamente que es una persona y no\nconvencional. El cerebro humano corresponde al de un unobjetouotroserbiológico. Debidoaestascaracterísticas\nsistemaaltamentecomplejo,no-linealyparalelo.Entérminos y muchas otras, las neuroredes se han convertido en una\nsencillos lo anterior equivale a decir que puede realizar gran ayuda en el procesamiento de datos experimentales\nmuchas operaciones simultáneamente a diferencia de los de comportamiento complejo. Además, su comportamiento\ncomputadores comunes que son de tipo secuencial, o sea, iterativonolineallasunedemodonaturalalcaosyteoríasde\nrealizan sólo una operación a la vez. En este sentido, una la complejidad. De hecho, las posibilidades son tan amplias\nneurored es un procesador de información, de distribución que se empieza a hablar de un nuevo campo, aparte de la\naltamenteparalela,constituidopormuchasunidadessencillas Biología,laMatemáticaylaFísica:lasNeurociencias.Como\nde procesamiento llamadas neuronas. La neuroredes se yalodijimos,loquesedeseainicialmenteesimitar,almenos\ncaracterizanprincipalmentepor: parcialmente, el funcionamiento del cerebro. Para hacerlo\nrevisaremos, superficialmente, algunos conceptos básicos de\n² Tenerunainclinaciónnaturalaadquirirelconocimiento\nneurobiología.\na través de la experiencia, el cual es almacenado, al\nigual que en el cerebro, en el peso relativo de las\nconexionesinterneuronales. 2. Neurobiología\n² Tienen una altísima plasticidad y gran adaptabilidad, Una neurona típica posee el aspecto y las partes que se\nson capaces de cambiar dinámicamente junto con el muestranenlafigura1. Sinembargo,debemosobservarque\nmedio. eldibujo noestáa escala, el axónalcanzaunlargotípicode\ncentímetrosyavecesdevariosmetros,lasdendritastambiény\n² Poseen un alto nivel de tolerancia a fallas, es\nlasterminalessinápticas,sonmáslargas,numerosasytupidas.\ndecir, pueden sufrir un daño considerable y continuar\nteniendounbuencomportamiento,aligualcomoocurre\nenlossistemasbiológicos.\n² Tener un comportamiento altamente no-lineal, lo que\nles permite procesar información procedente de otros\nfenómenosno-lineales.\nEntre las motivaciones principales para el estudio del\nfuncionamiento de las redes neuronales se encuentran los\nfenómenos neurológicos. Nuestro cerebro es un procesador\ndeinformaciónmuchísimomáseficientequeuncomputador.\nLa clave de esto se encuentra en la inmensa plasticidad del\nFigura1: Neuronaysuspartes.\ncerebro, existen tareas cotidianas para el cerebro que sería\nimpensable realizar mediante computación tradicional. Un Típicamente, las neuronas son 6 ó 5 órdenes de magnitud\nejemplo de esto es la capacidad reconocer a una persona en más lentas que una compuerta lógica de silicio, los eventos\nuntiempode100a200ms. Enesebrevelapso,elcerebroes en un chip de silicio toman alrededor de nanosegundos\ncapaz de procesar un patrón de información tridimensional, (10¡ 9 s), mientras que en una neurona este tiempo es del\n2 F.IZAUTIRETAYC.SAAVEDRA\norden de los milisegundos (10¡ 3). Sin embargo, el cerebro se transmitirá un pulso a lo largo del axón, en caso\ncompensa en forma excepcional la lentitud relativa en el contrario no transmitirá. Después de transmitir un\nfuncionamientoneuronalconunnúmeroinmensodeneuronas impulso, la neurona no puede transmitir durante un\ncon interconexiones masivas entre ellas. Se estima que el tiempo de entre 0,5 ms a 2 ms. A este tiempo se le\nnúmero de neuronas en el cerebro es del orden de 1010, y llamaperíodorefractario.\nqueel númerode conexiones sinápticas es 6£ 1013. Lared\nEn base a estas dos características, construiremos el\nresultante que es el cerebro es una estructura enormemente\nmodeloderedneural.\neficiente. Específicamente, la eficiencia energética del\ncerebroesaproximadamentede10¡ 16J=(operaciones£ s),\nlacualesdelordende1010vecesmayorqueladelosmejores 3. ModeloNeuronal.\ncomputadoresenlaactualidad.\nAquí se desea introducir un modelo sencillo de la\nLa mayoría de las neuronas codifican sus salidas como\nneurona, para construir redes, nuestro fin último es modelar\nuna serie de breves pulsos periódicos, llamados potenciales\ncorrectamenteelcomportamientoglobaldetodalared.Nose\nde acción, que se originan cercanos al soma de la célula y\npretendemodelarexactamenteelcomportamientofisiológico\nse propagan a través del axón. Luego, este pulso llega a las\nde la neurona, sino más bien sólo sus características más\nsinapsisydeahíalasdendritasdelaneuronasiguiente.\nrelevantes, queentranenjuegoensuinteraccióncontodala\nUnasinapsisesunainterconexiónentredosneuronas,un\nred.\ndibujoesquemáticodeellaseincluyeenlafigura2. Enella,\nTenemos un esquema de neurona en la figura 3. En él\nel botón sináptico corresponde al término del axón de una\nnuestraneuronade interés es la y . Lasn neuronas x están\nneurona pre-sináptica, y la dendrita es la correspondiente a j i\nenviando señales de entradas, que sonlos valores numéricos\nunaneuronapost-sináptica.\nde“algo”.Losvaloresw representanlospesossinápticosen\n50 nm las dendritas de y . Obsérvese la notación: el primer índice\ndenota a la neurona hacia donde se dirige la información, el\nsegundoíndicedenotadequéneuronaprocedelainformación.\nBotón Sináptico Dendrita\n1 ϕϕϕϕ\n(y (in) )\nw j v\nj1 1j\nFigura2: Saltosináptico x w y\ni ji j\nEl tipo más común de sinapsis es la sinapsis química, que w v\nfuncionacomosigue.Unaseñalneuraleléctricapre-sináptica, j0 2j\nllega al botón sináptico de la figura 2. Allí, ésta hace que x\nlasvesículassinápticas(enazulennuestrafigura)serompan, n\nliberándoseasí una sustanciallamada neurotransmisor. Esta\nFigura3:EsquemadeNeurona.\nsustancia química se difunde a través del espacio entre las\nLo que hace cada peso sináptico es simplemente multiplicar\nneuronas. Luego, es captada por la dendrita, en donde\nasuentradacorrespondientey define la importanciarelativa\nestimula la emisión de un nuevo impulso eléctrico, post-\nde cada entrada. Recordemos que en el soma de la neurona\nsináptico, que se propaga hacia la derecha. Así vemos que\nbiológica se sumaban las entradas provenientes de todas las\nlasdendritassonlaszonasreceptivasdeunaneurona,siendo\ndendritas. Entoncestenemosquelaentradatotalalaneurona\nel axón una línea de transmisión, y los botones terminales\ny es:\ncomunicanlosimpulsosaotrasneuronas. j\nEn la neurona, hay dos comportamientos que son\nimportantísimosparanosotros: y(in) = w x (1)\nj ji i\ni=1\n- El impulso que llega a una sinapsis y el que sale\nEn donde el índice (in) denota “input” o entrada. Como\nde ella no son iguales en general. El tipo de pulso\nmencionamoslaneuronaseactivasilaentradatotalsuperaun\nque saldrá depende muy sensiblemente de la cantidad\nciertoumbral.Loquesehaceparaestoesaplicarunafunción\nde neurotransmisor. Esta cantidad de neurotransmisor\nde activación ' sobre y(in), que puede ser, por ejemplo,\ncambiaduranteelprocesodeaprendizaje,esaquídonde j\nuna función tipo escalón o sigmoidea, como la tangente\nse almacena la información. Una sinapsis modifica el\nhiperbólica. Entoncestenemosquelaseñaldeoutputosalida\npulso,yaseareforzándoloodebilitándolo.\ndelaneuronay es:\n³ ´\n- Enelsomasesumanlasentradasdetodaslasdendritas. y = ' y(in) (2)\nSiestasentradassobrepasanunciertoumbral,entonces j j\nREDESNEURONALESARTIFICIALES 3\n3.1. FuncionesdeActivación.\nAlgunas funciones de activación típicas, no lineales, se\npresentanenlasfiguras4y5.\ny y\ny(in) y(in)\nFigura4:Escalón. Figura5: Sigmoidea.\nEstas funciones evidentemente transmiten la idea de Resulta mucho más compacto y práctico añadir lo que se\n“dispararsobreunumbral”. Lasneuronasysusfuncionesde llama una neurona de inclinación, x , a la que se asigna un\nactivaciónsedividenendostipos:bipolaresoantisimétricasy valor fijo de 1, y un peso sináptico w . A la neurona y le\nj0 j\nbinarias. Enlasprimeras,-a· y · a,siendogeneralmente asignamosunumbralfijodecero.\na = 1, y en las segundas, 0 · y j · 1. Además, a veces Seveclaramentequeestoesequivalenteaquelaneurona\nsesueleusarcomofuncióndeactivaciónunarelaciónlineal, y tengaunumbralde¡ w . Entoncessetieneque:\nj j0\ngeneralmentelafunciónidentidad. Estaseusaporlogeneral\npara neuronas de entrada a la red o sensores. Esto se debe\na que evidentemente, lo que esperamos de un sensor es que Xn\nindiqueprecisamenteloqueestápercibiendo. y j (in) = w ji x i ; conx 0 = 1. (3)\nSi la función de activación de una neurona es lineal, i=0\ndecimosqueesunaneuronalineal,encasocontrario,decimos\nque es una neurona no lineal. Aquí, las neuronas lineales 3.3. ElComienzo:McCulloch-Pitts.\nse las representa por un cuadrado, y a las no lineales por un\ncírculo. Después de las definiciones previas, es conveniente revisar\nun ejemplo sencillo, pero muy instructivo, sobre el tema.\n3.2. UmbraleseInclinación. Esteconsisteenel primer modeloquese creóde redneural,\nel año 1943, antes de que se construyeran los primeros\nAnteriormente, se explicó que una neurona se activa o\ncomputadores.McCullocheraunsiquiatrayneuroanatomista\n“dispara” si su entrada total supera un cierto umbral. Ahora\ny Pitts un matemático. El primero pasó 20 años estudiando\nbien, muchas veces es deseable modificar este umbral,\nsobre cuál era la representación de un evento en el sistema\nhaciendomásdifícilquelaneuronadispare(subirelumbral)\nnervioso.Sumodelotienelassiguientescaracterísticas:\no más fácil (bajar el umbral). Es posible hacer esto\ndirectamente. Sinembargo,estosueleserunpocoengorroso\nalprogramar. - Lasneuronassondeltipobinario,[0;1].\n- Losumbralesylassinapsissemantienenfijas.\nx w - Lafuncióndeactivaciónesdeltipoescalón.\n1 j0 ϕϕϕϕ (y (in) )\nw j v\nj1 1j Ellos demostraronquetodas lasfuncioneslógicas sepueden\nx w y describirmediantecombinacionesapropiadasdeneuronasde\ni ji j\neste tipo, y que por lo tanto, se podía crear, en principio,\nw v\nj0 2j una red capaz de resolver cualquier función computable.\nAdemás, el modelo sirve para explicar algunos fenómenos\nn biológicos sencillos. De esta forma es posible describir\nalgunasfuncioneslógicascomo:\nFigura6: EsquemaconInclinación.\n4 F.IZAUTIRETAYC.SAAVEDRA\nx x y x x y\n1 2 x 1 2 x\n1 1 1 1 1 1 1 1 1 2\n0 1 0 y 0 1 1 y\n1 0 0 1 0 1\nx x\n0 0 0 2 1 0 0 0 2 2\nFigura7: FunciónAnd Figura8: FunciónOr\nEntodosestosejemplos,sesuponequeelumbraldecadaneuronanolineales2. Osea,\n0siyin < 2\ny= (4)\n1siyin ¸ 2\nAhoraesmuyfácilcomprobarquelastablasdeverdadefectivamentesecumplen1,porejemplo,laprimeralíneadelatablade\nverdadparaelAnd:\n1£ 1+ 1£ 1= 2= yin ) y= 1\nVeamosunafunciónlógicamás: elxOruOrexcluyente.\nx x z\n1 2 2 y\n1 1 0 1 -1 1 2\n0 1 1 z\n1 0 1 -1\nx y\n0 0 0 2 2 2\nfig9: FunciónxOr.\nEs fácil comprobar que la red mostrada efectivamente\ncumpleconlatabladeverdad.Sinembargo,llamalaatención neuronadeinclinación,envezdeunumbral.\nel que su red sea más compleja que la de las funciones And\nu Or, pese a que sólo se diferencia de la función Or en la\nprimeralínea.Pudiéramosdarnoseltrabajodebuscarunared\n1 x w\ndiferente para representar xOr, buscando algo más sencillo. 0 0\nExisten varias otras redes que también la representan, pero\nningunadeellassencillascomolaparaAnduOr. x\nFijémonosprimeroenqueconsistela“complejidad”. En 1 1\nlas redes And u Or las neuronas de entrada y la de salida\nestánconectadasdirectamente,encambio,sepuededemostrar\nque para la función xOr habrá siempre por lo menos, una\nconexión indirecta. Para entender esta diferencia se debe x\nincorporar dos nuevos conceptos: Problemas linealmente 2 2\nseparablesyCapasNeurales. Figura10: FunciónLógica“simple”.\nSabemosquelaentraday(in) estarádadapor:\n3.4. ProblemasLinealmenteSeparablesyCapasNeurales.\n3.4.1. ProblemasLinealmenteSeparables.\ny(in) = w + w x + w x ; (5)\n0 1 1 2 2\nVolvamosaunaredsimple,comoladelAnduOr,peromás\ngeneral,comoladelafigura10.Enella,hemosañadidouna ylarespuesta,por:\n1Seasumeque1=Verdaderoy0=Falso.\nREDESNEURONALESARTIFICIALES 5\nMediante simple inspección podemos comprobar que\n0siy(in) < 0 efectivamenteesimposibleencontrarunalínearectaquedeje\ny= (6)\n1siy(in) ¸ 0 aunladolasentradasquedebenproducir0,yalotro,lasque\ndebenproducir1. Enestecaso, decimosqueelproblemano\nEstodividealplanoformadoporx yx endosregiones: en\n1 2 eslinealmenteseparable. Poresononosbastaconunared\nuna,setendráquey = 0ey(in) < 0,enlaotrasetendráque\n“sencilla”pararesolverelxOr.\ny = 1ey(in) ¸ 0. Lafronteraentreambasestádadaporla\nLo que en realidad estamos haciendo es un caso muy\necuaciónlinealdelarecta:\nsencillo del problema general de clasificación de patrones.\nEstamos clasificando las entradas en “Clase 1” o “Clase\nw 0 + w 1 x 1 + w 2 x 2 = 0: Verdadera”y“Clase0”o“ClaseFalsa”.\nEl concepto de separabilidad lineal se extiende de modo\nVeamos por ejemplo que ocurre con la función And.\nTenemosquey(in) = x + x ¡ 2,lafronteraesx + x = 2: natural a entradas de más dimensiones. Las entradas que\n1 2 1 2\npertenecen a una clase y las que no pertenecen a esta\nSi superponemos las respuestas que nos debe arrojar la red\nsimplemente tienen que poder separarse por el hiperplano\nconelgráficodelasregiones,obtenemoslafigura11.\nw x = 0enelespaciox delasentradas.\nji i\ni=0\nx +x =2\n1 2\nx No - Linealmente\n2 Linealmente Separable:\nSeparable:\nClase 1 ΣΣΣΣ w x= 0\n1 0 1 i = 0 ji i\nClase 1 Clase 1\nClase 0\n0 0 0\nx 1 Clase 2\n0 1\nClase 2 Espacio x\nFigura11: Andsobreelplano.\nSilaentradaestáenlaregión“Clase1”produciráunasalida\n1, si está en la “Clase 0”, una salida de 0. Vemos que se\nFigura13: SeparabilidadLineal.\npueden separar las entradas que deben producir una salida 1\ndelasquedebenproducirunasalida0porunalínearecta. Se Para aclarar el concepto de redes sencillas primero\ndiceentoncesqueelproblemaeslinealmenteseparable. Para revisaremosotroconcepto: lasCapasNeurales.\nresolverunproblemalinealmenteseparable,nosbastaconuna\nred“sencilla”. 3.4.2. CapasNeurales\nRevisemos en cambio, como es la función xOr sobre el\nCuando trabajamos con grandes cantidades de neuronas,\nplano:\nes natural ordenar aquellas que tienen comportamientos\nsimilares en “capas”, como en la figura 14. De ahí que se\nx usenlossubíndicesparalasneuronas. Cadacapaesunvector\ndeneuronas.\n1 1 0\n0 0 1\n0 1\nFigura12: xOrsobreelplano.\n6 F.IZAUTIRETAYC.SAAVEDRA\n1= x w\n0 j0\nx w y\nj1 1\nx w y\ni ji j\nx w y\nm jm n\nadartnE adilaS\nCapa 0 Capa 1\nFigura14: RedUnicapa.\nSe acostumbra no contabilizar la capa de entrada, por lo tanto se dice que la red de la figura 14 es “Unicapa”. Las sinapsis\nobviamenteestánordenadasenunamatrizw den£ (m+ 1).Evidentemente,denuestroanálisisanterior,tenemosqueunared\nunicapasólopuederesolverproblemaslinealmenteseparables. Enunaredunicapa,lasneuronasdesalidapuedenserlinealeso\nnolineales.\nPeroesevidentequepodemosseguirañadiendocapas,comosemuestraenlafigura15.\n1= x u\nj0 0\nx u\nj1 1\nx u\nji i\nx u\nm jm\nadartnE\ny v\n0 k0\nv z\nk1 1\nv z\nkj k\nz w\nkn p\nCapa 0 Capa 1 pn Capa 2\nadilaS\nFigura15: RedMulticapa.\nREDESNEURONALESARTIFICIALES 7\nEn una red multicapa, las capas ocultas, que en nuestra ² Luego, conlaseñaldeerror e (n),corrijolassinapsis\nfigura correspondea la Capa 2, siempre son nolineales. Se delaredmediantealgúnalgoritmodelosqueseveráa\npuededemostrarmuyfácilmentequesiseconstruyeunared continuación. “Nohijo,estanoesunaE,esunaA...”.\nmulticapaconcapasocultaslineales,éstaesequivalenteauna\nredunicapa.\nPodemosverfácilmentelaideadeparalelismoalobservar\nlascapasdelasredes. Cadaneuronadeunacapanonecesita\nde las demás en su misma capa para trabajar, son capaces Profesor\npor lo tanto de trabajar simultáneamente. Esta cualidad {x(n);d(n)}\ni j d (n)\nse ha aprovechado al diseñar chips paralelos con la nueva x (n) j\ntecnologíaVLSI (VeryLargeScaleIntegrated), endondese\nhanimplementadovariostiposdeneuroredes. o (n) -\nUna red multicapa es capaz de resolver problemas más j ΣΣΣΣ\ncomplejos, pero su proceso de aprendizaje también es más Neurored\ncomplicado.\ne (n)\n4. AprendizajeoEntrenamiento. j\nFigura16: AprendizajeconProfesoroSupervisado.\nEl aprendizaje es la clave de la plasticidad de una neurored\ny esencialmente es el proceso en el que se adaptan las La secuencia completa de los N pares de entrenamiento es\nsinapsis, para que la red responda de un modo distinto a los conocidacomounaÉpoca.Engeneral,puedenhabermuchas\nestímulosdelmedio. Recordemosqueenunaneurored,toda épocas, y el aprendizaje se detiene cuando la red responda\nla información adquirida se guarda en el valor de cada peso correctamenteatodoslosparesdeentrenamiento.\nsináptico. De hecho, las neuronas de la mayor parte de los En general, cuando adaptemos las sinapsis, la forma de\nseres vivos con sistema nervioso, desde un caracol hasta el hacerloserámediantelasiguienteecuación:\nhombre son esencialmente iguales. Lo que nos hace más\ninteligentesqueuncaracoleselnúmero,organizaciónymodo\nde cambio de las conexiones sinápticas. El aprendizaje se w (n+ 1) = w (n)+ ¢w (n) (7)\nji ji ji\ndivideprincipalmenteendostipos: AprendizajeconProfesor\noSupervisadoysinProfesoroNoSupervisado.Nosotrossólo en donde w (n) son los pesos sinápticos con los que\nestudiaremosaprendizajeconprofesoryalgunasvariantesde la red responderá al n-ésimo ejemplo. Esto equivale a\néste. no cambiar los pesos sinápticos en forma radical, sino\nque simplemente los variamos en una cantidad “pequeña”\n4.1. AprendizajeconProfesoroSupervisado. ¢w (n) conrespectoasuestadoanterior. Loquediferencia\nalosalgoritmosoreglasdeaprendizaje,esbásicamentecomo\nEl proceso es completamente análogo a enseñarle algo a un\nencontrar ¢w (n). El que hayan distintos algoritmos tiene\nniño,digamosporejemplo,areconocerlasvocales.Lospasos ji\nciertabasebiológica.Neuronasdedistintaspartesdelcerebro\ndelprocesosonlossiguientes:\naprendendeformadistintatambién.\n- El profesor dispone de un conjunto de N pares de\nentrenamiento, fx (n);d (n)gN , en donde x (n) es 4.2. RegladeHebb.\ni j n=1 i\nla n-ésima entrada y d (n) es la respuesta correcta a\nesaentrada. Ennuestroejemplo,significaquetenemos Esta es la más antigua y la más famosa de las reglas\ntodaslasvocalesdibujadasenunpapel(x (n) )yque de aprendizaje, su base es completamente biológica. Fue\nnosotros sabemos las respuestas correctas ( d (n) ) a encontrada por el neurofisiologo Hebb en 1949, quien\ncadaunadelasfiguras,lossonidosA,E,I,O,U. descubrió que si dos neuronas a ambos lados de la sinapsis\nestaban activas (o inactivas) simultáneamente, entonces las\n- Introducimos una de las entradas x i (n) y esperamos sinapsis entre ellas se reforzaban, y si se activaban (o\nque nuestra red nos responda. Sería como mostrarle desactivaban) asincrónicamente, se debilitaban. Una forma\nal niño la letra A y preguntarle: “Dime, ¿Qué letra es\ndeexpresarestaideadeformasencillaeslasiguiente:\nesta?”.\n² La neurored responde mediante una salida o (n).\n¢w (n) = ´y (n)x (n); ´ > 0; (8)\nDigamos,elniñonosrespondió“EsaesunaE”. ji j i\n² Luego comparamos ambas señales, la respuesta dondelascapasdeneuronasx ey estándistribuidascomoen\ni j\ndeseada d (n) y la respuesta de la red o (n), creando lafigura14. Alaconstantedeproporcionalidad´ selellama\nj j\nunaseñaldeerror,e (n) = d (n)¡ o (n).“Mmm...el “razóndeaprendizaje”.Paravercomofunciona,supongamos\nj j j\nniñonoestátandespiertocomoesperaba...”. quex e y sonbipolares oantisimétricas, con a = 1. Six\ni j i\n8 F.IZAUTIRETAYC.SAAVEDRA\ne y toman ambas simultáneamente el valor de 1 (o de -1), ser un receptor, es capaz de reconocer el movimiento y\n¢w (n) = ´,yesasinapsissereforzará. Encambio,siuna\ntomase el valor -1 y la otra el de 1, ¢w (n) = ¡ ´, y esa bordes,ypuedeadaptarseacambioslocalesenelbrillo.\nsinapsissedebilitará. Un perceptrón es una red de una sola capa, como la de\nEsteaprendizajeexplicaelfamosoexperimentodePavlov. la figura 14. Las neuronas de salida son no lineales, con\nÉlledabaalimentoaunperroysimultáneamentetocabauna funcióndeactivacióntipoescalón. Ennuestrosexperimentos\ncampanilla. Después de repetir esto muchas veces, Pavlov numéricos, utilizamos funciones de activación bipolares o\ntocó sólo la campanilla, sin alimento. Y el perro, sólo antisimétricas,comolasiguiente:\noyendolacampanilla,salivaba.Laexplicaciónesmuysimple.\nAl activarse simultáneamente las neuronas que controlan la 8\nsalivaciónylasquepercibenlacampanilla,lassinapsisentre >< ¡ 1siy\n(in) < 0\nellasserefuerzan. y = 0siy(in) = 0 (9)\nj >:\n1siy\n(in) > 0\n4.3. AprendizajepararedesUnicapa. j\nNótese que se incluyó un punto neutro. A este se le suele\n4.3.1. RegladeAprendizajeperceptrónico.\nllamar punto de indeterminación. A veces incluso se usa\nObjetivo y funcionamiento general: Esta regla unaregiónentornoalorigenqueproduceunasalidadecero,a\nde aprendizaje está diseñada especialmente para el lacualselellamabandadeindeterminación. Simplemente\nreconocimiento de patrones, pero por ser red unicapa, dicequelaneuronanosabequeresponder. Cadaneuronade\nsólo se pueden usar patrones linealmente separables. El salida representa a una clase determinada, si una de ellas se\nperceptrónnaciócomounprimerintentodemodelarlaretina, activa con una entrada, significa que pertenece a esa clase,\nen 1958, por Rosenblatt. Es usual pensar que la retina es si está desactiva, que no pertenece. Aquí, incluimos dos\nsimplemente un receptor (como el detector CCD de una experimentos al respecto, clasificando imágenes de letras.\ncámara de vídeo), pero en realidad es una red altamente La entrada x i corresponde al i-ésimo píxel de la imagen.\ncompleja. Sólohapodidoserreproducidaenojospararobots Digamos por ejemploque tenemos unaredque nos clasifica\nyretinasartificialesparaciegosenlaúltimadécada,mediante una entrada como X u O. Lo que queremos es que funcione\nlosllamadoscircuitosneuromórficos. Laretina,ademásde comosemuestraenlafigura17,endondelaneuronamarcada\nconXreconocealaclaseX,ylaconO,alaclaseO:\nx 1: “Es una X”\nO -1: “No es una O”\nx -1: “No es una X”\nO 1: “Es una O”\nFigura17: FuncionamientodeunPerceptrón\nAlgoritmo Perceptrónico. Veamos ahora como entrenar 1;:::;N,hacerlospasosdel3y4.\nestaredquecuentam ym númerodeneuronasdeentrada\no 1\ny salida respectivamente. Además, existen N pares de\nentrenamientofx (n);d (n)gN .Deestaformaelalgoritmo Paso3: j = 1;:::;m\ni j n=1 1\nes:\nPaso0: Inicializar las sinapsis de la red, se puede elegir Xm0\ny(in)(n) = w (n)x (n)\nw ji (0) = 0 ó valores aleatorios. se elige una razón j ji i\ndeaprendizaje´,0< ´ · 1. i=0\nPaso1: Mientraslacondicióndeparadadelpaso5seafalsa,\n>< ¡ 1siy\n(in)(n) < 0\nrealizarlospasosdel2al5. y j (n) = >: 0\n) =\nPaso2: Paracadapardeentrenamiento,(x i (n);d j (n));n = j\nREDESNEURONALESARTIFICIALES 9\nPaso4: Si y (n) 6= d (n), para algún j entre 1 y m , el mismo hiperplano de separación, aunque distintos pesos\nj j 1\nentonces sinápticos. Además, generalmente, noes un solohiperplano\nelquenospodríadelimitarbienlafrontera,sinoquemásbien\nw (n+ 1) = w (n)+ ´d (n)x (n);\nji ji j i hayinfinitos,comosemuestraenlafigura18:\ndondej = 1;:::;m ;i = 0;:::;m . Encaso contrario\n1 0\nw (n+ 1) = w (n)\nji ji\nPaso5: Silospesossinápticosnocambianparacadapatrón\ndeentrenamientodurantelaúltimavezqueserealizóel Clase 1\npaso2,entoncesparar,sinoesasí,continuar.\nSe ve claramente que en nuestro caso, ¢w (n) =\n´d (n)x (n)o0,dependiendodesihuboerrorono.Podemos\nj i\nentender intuitivamente el algoritmo de la siguiente forma.\nSupongamos que la j-ésima neurona respondió de forma Clase 2\nincorrecta,dijo-1envezde1.Estosignificaquey(in)(n)fue\ndemasiadopequeño,debemoshacerquecrezcahaciendoque\nmP0\nmástérminosenlasumatoria w (n)x (n) seanpositivos\nji i\ni=0\ny lo máximo posible. O sea, si la i-ésima entrada, x (n) es Espacio x\n+1,entonceslai-ésimasinapsis,w (n),debieraserpositiva\nylomásgrandeposibletambién: debemoshacerlacrecer. Si Figura18:InfinitasSoluciones.\npor el contrario, x (n) es -1, debemos hacer bajar a w (n).\ni ji Osea,onoexisteningunasolución,oexisteninfinitas.\nEsoesloquesere(cid:31) ejaenlaformaenquehemosconstruido\nEs posible demostrar que si existe solución, entonces\nel¢w (n),sid (n)es+1,entonces¢w (n)tieneelmismo\nji j ji el algoritmo perceptrónico convergerá a una de las infinitas\nsignoquex (n).Enelcasocontrario,estodoalrevés.\ni solucionesenunnúmerofinitodepasos.\nEs bastante evidente que si un problema es linealmente\nseparable, existen infinitos pesos sinápticos que servirán\npara solucionar el problema. Basta con multiplicar por una Experimentos Computacionales. A modo de ejemplo se\nPn incluyen dos experimentos (computacionales), ambos de\nconstantelaecuación w x = 0yseguimosteniendo\nji i clasificacióndeletras. Paraelprimero,usamoslassiguientes\ni=0\nentradas:\nFigura19: PatronesdeentrenamientoparaelExperimento1\nCadaimagenesde7£ 9= 63píxels,unpíxelnegrocorrespondeaun+1yunoblancoaun-1,seusó´ = 1. Lassinapsis\nseinicializaroncon0. Paraconstruirelvectorx deentradas,simplementeponemosunafiladelaimagendespuésdelaotra.\nDespuésdelentrenamiento,algunospatronesquefueronclasificadoscorrectamentefueronlossiguientes:\n10 F.IZAUTIRETAYC.SAAVEDRA\nA C D E K\nAquí observamos el funcionamiento de la red que se ha\nconstruido,queapesardesermuysimple, tieneplasticidad\ny es capaz de generalizar. A pesar de que nunca vio esos\npatrones con errores durante su entrenamiento, fue capaz de 4\nreconoceraquéletracorrespondían.\nParaampliarelexperimentonospreguntamos: ¿Sepodrá 0\nrealizarconpatronesmásgrandes? y,¿Quéimagenpodemos\nhacernosdecómoestándistribuidaslassinapsis?\nPararesponderesaspreguntas,construimosunperceptrón\nX O I\nque sólo clasificara entre X, O e I, pero con entradas de\nuna resolución mucho mayor: 56 £ 72 = 4032 pixeles.\nTrabajamosexactamentedelmismomodoqueconelejemplo Figura23:SinapsisparaX,OeI.\nanterior. Los patrones de entrenamiento ahora son los\nsiguientes: Simplemente observandose puede entender cómofuncionan\nlas sinapsis, y qué regiones son más cruciales que otras al\nreconocerelpatrón.\nPero dijimos que las sinapsis no eran únicas. Si\nempezamos con valores iniciales aleatorios llegamos a otro\ntipodeconexionessinápticas,comoestas:\nX O I\nFigura24: OtrasSinapsisparaX,OeI.\nFigura21: Patronesdeentrenamiento,2 Ahora, pasaremos a otra tarea que realizan muy bien las\nneuroredes: predecir.\nSe necesitaron sólo tres épocas. Algunos patrones que\nfueronclasificadoscorrectamente,son:\n4.3.2. ReglaDelta,ocorreccióndeerror.\nEstaesunareglamuypopular, enellaseusaunareddeuna\nsolacapa,igualquelaperceptrónica,perolaneuronadesalida\ntiene una función de activación derivable, generalmente la\nfunción identidad o la tangente hiperbólica. Para esta regla,\nusamosunalgoritmomássencillo,simplementecalculamosel\nerrore (n) = d (n)¡ y (n) correspondienteacadaentrada,\nX O I j j j\nyluegocorregimoslassinapsisdelaredmediantelaregla:\nNuevamente observamos la plasticidad. Pero, ¿cómo se\ndistribuyen las sinapsis?. Para verlo de un modo gráfico,\nsimplemente reordenamos en la misma forma de la imagen ¢w (n) = ´e (n)' 0(y(in)(n))x (n) (10)\nji j j j i\noriginalalassinapsis, obteniéndose3gráficas: Unaparalas\nsinapsisqueseconectanconlaneuronadelaX,otraconlade Si las neuronas de salida tienen a la identidad como\nlaOyotraconladelaI. funcióndeactivación,' 0(y(in)(n)) = 1,yentonces,\nj j\nREDESNEURONALESARTIFICIALES 11\nen nuestro experimento simplemente recurrimos al ensayo y\n¢w (n) = ´e (n)x (n)\nji j i error,quesuelesermuchomásrápido.\nque es la forma más común del algoritmo. Esta regla en\nrealidad es un caso particular muy sencillo del algoritmo de Predictorlineal,ofiltroLinealAdaptativo. Supongamos\nretropropagacióndeerrores. quetenemosunsistemadinámicoalqueestamosdescribiendo\nLa convergencia del algoritmo depende fuertemente del por un único parámetro x. Lo único que conocemos de él\nvalor de´. Siseeligeunomuypequeño, laconvergenciase es su historia, muestreando x cada cierto período T. Lo\nharámuylenta,ysiseeligemuygrande,elprocesosevolverá que queremos hacer es predecir cuál será la respuesta del\ninestable y no convergerá. Existen criterios para determinar sistema en el próximo instante. Esto lo hacemos mediante\ncotassuperiorespara´,perosuelensercomplicados,nosotros una interacción red - sistema dinámico comola mostrada en\nlafigura25:\nx( [n+1]T )\nx( nT )\nn +\nx( [n+1]T )\nSistema\nx( iT ) ΣΣΣΣ\nw ˆ\ni x -\nDinámico\ne(n)\nx( T ) w\n∆∆∆∆w(n)\nfigura25: PredictorLineal\nAquívemosqueelpapeldeprofesoresllevadodemodo\nautomático por el mismo sistema dinámico. La red conoce Se puede observar fácilmente que a medida que la red va\ntodaslasentradasdesdex(T) hastax(nT), ydebepredecir aprendiendo,cadavezescapazdepredecirmejor.\nel valor de x([n+ 1]T). El papel de respuesta deseada lo\njuega x([n+ 1]T) y el de entrada el historial del proceso.\n4.4. AprendizajeparaRedesMulticapa.\nEs completamente análogo al proceso de aprendizaje con\nprofesor, excepto por que el número de neuronas de entrada\nAhora, romperemos con nuestras limitaciones anteriores y\ndebeaumentarconstantemente.\nestudiaremoselcasonolineal. Debemosrecordarqueeneste\ntipoderedes,lasfuncionesdeactivacióndelascapasocultas\nExperimentocomputacional. Usamos un ´ = 0:01yuna\nsonsiemprenolineales. Además,veremosdelasecuaciones\nneurona de salida con la funciónidentidad. Nuestro sistema\nque necesitamos una función de activación diferenciable en\ndinámicoeraunaseñalsenoidalconvariacionesaleatorias.\ntodo su dominio. Además, se encuentra que el algoritmo\nde aprendizaje es más difícil de visualizar. Nosotros\nsólo estudiaremos un tipo de aprendizaje, el Aprendizaje\n1 Sist. Dinámico. RetropropagadordeError.\n0.8\n0.6 Neurored\n0.4\nx 0.2 4.4.1. EstructurayNotacióngeneral\n-0.2\nLaestructuradelaredsemuestraenlafigura27, lacapade\n-0.4\n-0.6 salidaeslacapaL-ésima,ytienem neuronas.Ladeentrada\n-0.8 es la capa 0, y tiene m neuronas. Decimos que nuestra red\n-1 0\ntiene L capas, a L se le llama a veces la profundidad de la\n50 100 150 200 250\nTiempo [ T ] red.\nFigura26: ExperimentodePredicción.\n12 F.IZAUTIRETAYC.SAAVEDRA\nm m m ... m m m\n0 1 2 L-2 L-1 L\nadartnE\nadilaS\nFigura27: RedMulticapa.\nSupondremos que cada capa tiene sus neuronas de laseñaldesalida.\ninclinación, que por lo general no dibujaremos en los\ndiagramas. En general, las neuronas de cada capa están\n- Señales de Error: Luego de la etapa hacia adelante,\ncompletamenteconectadasconlasdelasiguiente.\nvienelaretropropagacióndelerror,haciaatrás.Cuando\nEn el funcionamiento de nuestra red, nos encontraremos\ncorregimos las sinapsis, corregimos las de la capa L\ncon dos tipos de señales: Señales de Función y Señales de\nprimero. Luego, observandolas sinapsisdelacapaL,\nerror.\ncorregimos las de la capa L ¡ 1, y así sucesivamente\n- Señales de Función: Es el estímulo que entra en la hasta la primera capa. A esto se le llama señal de\ncapa0, ypasahaciaadelante, capaporcapadelmodo error,vamosdesdelasúltimascapashastalasprimeras\ntradicional,hastalaúltimacapa,L,endondesegenera corrigiendo sinapsis. Esto es lo que se ilustra en la\nfigura28:\nSeñal de Función\n2 Etapas:\nSeñal de Error\nFigura28: Etapashaciaadelanteyhaciaatrás.\n4.4.2. Definiciones.\nMuchos físicos han trabajado en este campo, y han\nError: Supongamos que la capa de salida está constituida empleadotérminosdelaFísica.\npor las neuronas z . Entonces, el error cometido al\npresentarseeln-ésimopardeentrenamientoes:\nEnergía promedio de error. Es el promedio de la energía\nde error durante una época completa de presentación de\npatrones.\ne (n) = d (n)¡ z (n): (11)\nk k k\n“Energía”deerror: La“energía”deerroralpresentarseel 1\n\" = \"(n) (13)\nn-ésimopardeentrenamientoes: pro N\nn=1\ndonde \"(n) y \" son funciones de todas las sinapsis de la\npro\n1XmL\nred. El objetivo del proceso de aprendizaje será minimizar\n\"(n) = e2(n) (12)\n2 k \" pro . Sea w ji una sinapsis cualquiera de la red. Es fácil ver\nk=1\nque\" (w )y\"(n)(w )constituyensuperficiesdeerror. La\nav ji ji\nEstanoesunaenergíafísica,enlajergadelasneuroredessólo idea del algoritmo será la del descenso paso a paso. Vamos\nselellamaasíporsuformaanálogaalaenergíacinética. a hacer una primera aproximación para aclarar conceptos.\nREDESNEURONALESARTIFICIALES 13\nEl gradiente de \" señala su dirección de crecimiento. Se puede intentar evitar estotratando de minimizar las \"(n)\nEvidentemente,vienedadopor: envezde\" ,perodeunmodobienespecial,comoseexplica\npro\nenlasiguientesección.\n@\" (w ) = pro: (14)\nji pro ji @w\nSiqueremosminimizar\" ,deberíamosdirigirnosencontra\npro\ndelgradiente,comovemosenlasiguienterelación: 4.4.3. IdeadelAlgoritmo.\nw ji (p+ 1) = w ji (p)¡ ´ pro (15) Intentaremosminimizar\" av minimizandolas\"(n). Esdecir,\n@w ji (p) tendremosque:\nEn donde p simplemente señala que estamos en el p-ésimo\npaso. Loqueestamoshaciendoes“esquiar”o“resbalarnos”\nsobre la superficie de error, tratando de llegar al mínimo\n@\"(n)\nglobaldelasuperficie.Sinembargo,haciendoesto,corremos\nw (n+ 1) = w (n)¡ ´ : (16)\nel peligro de quedar atrapados en un minímo local de la ji ji @w ji (n)\nsuperficie,ynuncaalcanzarelmínimoglobal,comoseilustra\nenlafigura29.\nCada patrón que se presenta tiene una superficie de\nerror \"(n) diferente. Lo que hacemos es presentar el n-\nav ésimo par de entrenamiento y corregir todas las sinapsis\nde la red. Es decir tenemos la n-ésima superficie y nos\n“resbalamos”unpaso. Luego,presentamosel(n+ 1)-ésimo\npar de entrenamiento y corregimos nuevamente todas las\nsinapsis de la red. O sea, cambiamos de superficie y nos\n“resbalamos”otropaso. Esteconstantecambiodesuperficie\nhace muy difícil quedar atrapado en un mínimo local. Una\nw buena imagen mental sería estar esquiando en una montaña,\n¡que está temblando alocadamente!. Evidentemente, tarde o\ntemprano llegaremos al valle más profundo que exista. Este\npocesoseilustraenlafigura30.\nFigura29: Peligrodecaerenmínimolocal.\n(n+1)\n(n)\nFigura30: EsquivandoMinímosLocales.\nLo que estamos suponiendo implícitamente es que el\npromedio de los cambios individuales en las sinapsis es un mismo procedimiento, llamémoslo F. Entonces\nestimador del cambioquedebieraocurrir si minimizaramos estaríamositerando:\ndirectamente\" .\npro\nAdemás, el orden de presentación de los pares w ((n+ 1)-Época) = F(w (n-Época)) (17)\nji ji\nde entrenamiento se randomiza de época en época.\nEsto hace que la trayectoria seguida sobre la superficie Desde Teoría de Caos, sabemos que procesos como estos\nsea completamente estocástica. Supongamos que no puedenconvergeraestadosmetaestables,comocicloslímites.\nrandomizáramos el conjunto de entrenamiento. Entonces Para eliminar esta posibilidad se intenta randomizar el\ntendríamosqueépocatrasépocaestaríamosrepitiendoel conjuntodeentrenamiento,mediante:\n14 F.IZAUTIRETAYC.SAAVEDRA\n4.4.4. AlgoritmodeRetropropagacióndeError.\nw (1-Época) = F(w (0-Época))\nji ji\nw (2-Época) = G(w (1-Época)) Consideremos la red de la figura 31. No dibujamos las\nji ji\nsinapsis, sólo las señalamos con una (cid:31) echa. La red puede\nw (3-Época) = H(w (2-Época)),etc.\nji ji seguir teniendo más capas ocultas hacia atrás. Se puede\ndemostrarque:\n@\"(n)\n¢w (n) = ´ = ´± (n)y (n), k = 1;:::;m ; j = 0;:::;m (18)\nkj k j L L¡ 1\n@\"(n)\n¢v (n) = ´ = ´± (n)x (n), j = 1;:::;m ; i = 0;:::;m\nji j i L¡ 1 L¡ 2\nv w\nji kj\nx y z\ni j k\nm m m\nL-2 L-1 L\nadilaS\nFigura31: RedMulticapas.\nO sea, cada cambio en las sinapsis es directamente\nproporcional a las señales enviadas por la capa que se\nencuentra antes. ¢w / y ; ¢v / x , y así para todas\nkj j ji i\nlascapasdelared.\nSi la capa es de salida o si es oculta, el gradiente local\n± l = C ¡ ap @ @ a y \" l ( ( d i n n e ) ) S s a e li c d a a lc : uladeformasdiferentes. d d o e n l d o e s j ±(L = ) 1 d ; e :: l : a ;m ca L p ¡ a 1 d . e A m q á u s í a v d e e m la o n s te q . ue C e o l n ± l ( j a L s ¡ o 1) tra d s ep c e a n p d a e s\nocultas,sehaceexactamentelomismo,siemprelacorrección\n±(L)(n) = e(L)(n)' 0(z(in)), k = 1;:::;m (19) depende, dela mismaforma, de loque hayasucedidoenlas\nk k k k L\ncapasdemásadelante. Esaloquenosreferíamosconquela\nAñadimos el superíndice L (aunque con la notación que señaldeerrorvahaciaatrás.\nestamos usando no es estrictamente necesario) para recalcar\nque nos referimos a la capa de salida. Usamos ' 0, la 0 A este método, en donde evitamos los mínimos locales,\nsignifica derivada con respecto al argumento, y el subíndice se le llama Método Secuencial. Algunas veces, pese al\nkserefiereaquecadaneurona,engeneral,¡pudierateneruna riesgodecaerenmínimoslocales,seminimizadirectamente\nfuncióndeactivacióndistinta!. \" , llamándose a esto Método Grupal, que no es muy\nEste es el mismo resultado que teníamos para el filtro usado. Aunque las características estocásticas del método\nlinealadaptativodeunasolacapa. Asíqueahorasabemosde secuencialhacenqueevitecaeraunmínimolocal,hacenque\ndonde venía esa ecuación. Simplemente estábamos tratando sea muy difícil establecer teóricamente la convergencia. En\ndeminimizar\" av delaformayadescrita. cambio, con el método grupal, la convergencia a un mínimo\nCapasOcultas: local está garantizada con un mínimo de condiciones. Pese\na ello, el método secuencial es altamente popular, pues es\nXmL muy simple de implementar computacionalmente y además,\n±(L¡ 1)(n) = ' 0(y(in)(n)) ±(L)(n)w(L)(n); (20) efectivamentefuncionamuybienenunainmensamayoríade\nj j j k kj\nk=1 casosdifíciles.\nREDESNEURONALESARTIFICIALES 15\n5. Conclusiones poder construir computadoras con ellas, por lo menos en\nprincipio.\nEstetrabajohapretendidorealizarunapequeñaintroducción Otra características fundamentales que no podemos\naalgunascaracterísticasdeneuroredesconocidas. Dehecho, olvidar sonla Robustez yla Capacidadde Aprendizaje. Las\naún los estudios más avanzados que existen hoydía sobreel neuronassoncapacesdeimitarypredecirelcomportamiento\ntema están muy alejados de entender el funcionamiento del de sistemas dinámicos sin usar ningún modelo explícito, y\ncerebro,quefuesumotivacióninicial. Eltemaenrealidades capacesdereconocerpatrones,aunqueéstostenganerrores.\nmuy vasto. Sin embargo, pese a que hemos visto una parte Ademásdetodoeso,sonmuyinteresantesparalaFísica,\nínfimadeltotal,hemospodidoapreciaralgunascualidadesde tanto para procesar información como en sí mismas. En\nestemecanismodeprocesamientodeinformación. cuantoaestoúltimo,sehandescubiertointeresantesáreasque\nEnprimerdebemoslugardestacarqueesposiblemodelar relacionanlasneuroredesconlaTeoríadelaInformación,el\nelfuncionamientodeunaneuronaenformaextremadamente Caos,laMecánicaEstadística.\nsimple, y sin embargo, posee una gran capacidad, vemos la\nsencillez y la complejidad unidas de un modo maravilloso. 6. Bibliografía\nPor ejemplo, de describió la posibilidad de procesar\ncantidadesincreíblesdeinformaciónenformaparalela,deun [1] Laurene Fausett, Fundamentals of Neural Networks\nmodosencilloynatural. (Prentice-Hall,NewYersey,USA,1994).\nAl poder establecerse las funciones lógicas mediante la [2] SimonHaykin,NeuralNetworks(Prentice-Hall,New\ncombinación de neuronas vemos también la posibilidad de Yersey,USA,1999)."}
